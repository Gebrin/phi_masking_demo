{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4975a6d5-d454-4fbe-9dd2-c1f4c201000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from cryptography.fernet import Fernet\n",
    "import string\n",
    "import base64\n",
    "import hashlib\n",
    "import getpass\n",
    "import uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e649689-454a-45ce-94b8-f64434635c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_directories():\n",
    "    \"\"\"Create all required directories\"\"\"\n",
    "    directories = [\n",
    "        '../data', \n",
    "        '../results', \n",
    "        '../results/reversed_datasets', \n",
    "        '../config'\n",
    "    ]\n",
    "    for directory in directories:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            print(f\"Created directory: {directory}\")\n",
    "        else:\n",
    "            print(f\"Directory exists: {directory}\")\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "setup_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fbccae-9946-4e47-8ad2-c935c2064282",
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSION_ID = str(uuid.uuid4())[:8]\n",
    "print(f\"Session ID: {SESSION_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3419fa51-5982-4d59-8ef3-f3be16d11758",
   "metadata": {},
   "outputs": [],
   "source": [
    "PII_COLUMNS = {\n",
    "    'names': ['full_name', 'doctor_name'],\n",
    "    'addresses': ['address_street', 'address_city', 'address_zip'],\n",
    "    'dates': ['date_of_birth', 'admission_date', 'discharge_date'],\n",
    "    'contact': ['phone_number', 'email_address'],\n",
    "    'identifiers': ['ssn', 'license_number', 'vehicle_id', 'device_serial_number'],\n",
    "    'network': ['ip_address'],\n",
    "    'organizations': ['hospital_name', 'insurance_provider']\n",
    "}\n",
    "\n",
    "print(\"PII Column Categories:\")\n",
    "for category, columns in PII_COLUMNS.items():\n",
    "    print(f\"{category}: {columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec6e43-647b-4115-b6f7-417f0d2be5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIIDetector:\n",
    "    def __init__(self):\n",
    "        self.patterns = {\n",
    "            'email': r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n",
    "            'phone': r'(\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}(\\s*x\\d+)?)',\n",
    "            'ssn': r'\\b\\d{3}-?\\d{2}-?\\d{4}\\b',\n",
    "            'ip_v4': r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b',\n",
    "            'ip_v6': r'\\b(?:[0-9a-fA-F]{1,4}:){7}[0-9a-fA-F]{1,4}\\b',\n",
    "            'date': r'\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}',\n",
    "            'zip_code': r'\\b\\d{5}(-\\d{4})?\\b',\n",
    "        }\n",
    "        \n",
    "        self.pii_keywords = {\n",
    "            'name': ['name', 'first', 'last', 'full_name', 'doctor', 'patient'],\n",
    "            'address': ['address', 'street', 'city', 'state', 'zip', 'postal'],\n",
    "            'contact': ['phone', 'email', 'telephone', 'mobile'],\n",
    "            'id': ['id', 'ssn', 'social', 'license', 'serial', 'number'],\n",
    "            'date': ['date', 'birth', 'dob', 'admission', 'discharge'],\n",
    "            'organization': ['hospital', 'insurance', 'provider', 'company']\n",
    "        }\n",
    "    \n",
    "    def detect_pii_columns(self, df):\n",
    "        \"\"\"Detect PII columns based on column names and content patterns\"\"\"\n",
    "        pii_detected = {}\n",
    "        \n",
    "        for column in df.columns:\n",
    "            column_lower = column.lower()\n",
    "            pii_type = None\n",
    "            confidence = 0\n",
    "            \n",
    "            for pii_category, keywords in self.pii_keywords.items():\n",
    "                for keyword in keywords:\n",
    "                    if keyword in column_lower:\n",
    "                        pii_type = pii_category\n",
    "                        confidence += 0.7\n",
    "                        break\n",
    "            \n",
    "            sample_data = df[column].dropna().head(100).astype(str)\n",
    "            \n",
    "            for pattern_name, pattern in self.patterns.items():\n",
    "                matches = sample_data.str.contains(pattern, regex=True, na=False).sum()\n",
    "                match_ratio = matches / len(sample_data) if len(sample_data) > 0 else 0\n",
    "                \n",
    "                if match_ratio > 0.5:\n",
    "                    if pattern_name == 'email':\n",
    "                        pii_type = 'contact'\n",
    "                        confidence += 0.8\n",
    "                    elif pattern_name == 'phone':\n",
    "                        pii_type = 'contact'\n",
    "                        confidence += 0.8\n",
    "                    elif pattern_name in ['ip_v4', 'ip_v6']:\n",
    "                        pii_type = 'network'\n",
    "                        confidence += 0.9\n",
    "                    elif pattern_name == 'date':\n",
    "                        pii_type = 'date'\n",
    "                        confidence += 0.6\n",
    "            \n",
    "            if pii_type and confidence > 0.5:\n",
    "                pii_detected[column] = {\n",
    "                    'type': pii_type,\n",
    "                    'confidence': min(confidence, 1.0)\n",
    "                }\n",
    "        \n",
    "        return pii_detected\n",
    "    \n",
    "    def validate_pii_detection(self, df, detected_pii):\n",
    "        \"\"\"Display detection results for validation\"\"\"\n",
    "        print(\"PII Detection Results:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for column, info in detected_pii.items():\n",
    "            sample_values = df[column].dropna().head(3).tolist()\n",
    "            print(f\"Column: {column}\")\n",
    "            print(f\"  Type: {info['type']}\")\n",
    "            print(f\"  Confidence: {info['confidence']:.2f}\")\n",
    "            print(f\"  Sample values: {sample_values}\")\n",
    "            print()\n",
    "\n",
    "detector = PIIDetector()\n",
    "print(\"PII Detector initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cce1006-a468-478c-81a5-eda24d0b6d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIIEncryptionSystem:\n",
    "    \"\"\"Secure encryption system for PII mappings with user-defined encryption keys\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.key = None\n",
    "        self.fernet = None\n",
    "        self.encrypted_mappings = None\n",
    "        self.user_password = None\n",
    "        \n",
    "    def generate_encryption_key(self, user_password=None):\n",
    "        \"\"\"Generate encryption key from user password\"\"\"\n",
    "        if user_password is None:\n",
    "            user_password = getpass.getpass(\"Enter encryption password for this dataset: \")\n",
    "        \n",
    "        self.user_password = user_password\n",
    "        \n",
    "        # Generate key from password using PBKDF2\n",
    "        password_bytes = user_password.encode('utf-8')\n",
    "        salt = b'pii_masking_salt_2024'  # Fixed salt for consistency\n",
    "        key = hashlib.pbkdf2_hmac('sha256', password_bytes, salt, 100000)\n",
    "        \n",
    "        # Fernet requires base64 encoded key\n",
    "        self.key = base64.urlsafe_b64encode(key)\n",
    "        self.fernet = Fernet(self.key)\n",
    "        \n",
    "        print(\"Encryption key generated from password\")\n",
    "        return True\n",
    "    \n",
    "    def save_key_info(self, filepath):\n",
    "        \"\"\"Save key generation info (not the actual key)\"\"\"\n",
    "        key_info = {\n",
    "            'session_id': SESSION_ID,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'key_generated': True,\n",
    "            'note': 'Key generated from user password'\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(key_info, f, indent=2)\n",
    "        \n",
    "        print(f\"Key info saved to: {filepath}\")\n",
    "        return True\n",
    "    \n",
    "    def encrypt_mappings(self, mappings_dict):\n",
    "        \"\"\"Encrypt the mappings dictionary\"\"\"\n",
    "        if self.fernet is None:\n",
    "            print(\"No encryption key available!\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # Convert mappings to JSON string\n",
    "            mappings_json = json.dumps(mappings_dict, indent=2)\n",
    "            mappings_bytes = mappings_json.encode('utf-8')\n",
    "            \n",
    "            # Encrypt the mappings\n",
    "            encrypted_data = self.fernet.encrypt(mappings_bytes)\n",
    "            \n",
    "            self.encrypted_mappings = {\n",
    "                'session_id': SESSION_ID,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'encrypted_data': base64.b64encode(encrypted_data).decode('utf-8')\n",
    "            }\n",
    "            \n",
    "            print(\"Mappings encrypted successfully\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Encryption error: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def save_encrypted_mappings(self, filepath):\n",
    "        \"\"\"Save encrypted mappings to file\"\"\"\n",
    "        if self.encrypted_mappings is None:\n",
    "            print(\"No encrypted mappings to save!\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            with open(filepath, 'w') as f:\n",
    "                json.dump(self.encrypted_mappings, f, indent=2)\n",
    "            \n",
    "            print(f\"Encrypted mappings saved to: {filepath}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Save error: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def load_encrypted_mappings(self, filepath):\n",
    "        \"\"\"Load encrypted mappings from file\"\"\"\n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                self.encrypted_mappings = json.load(f)\n",
    "            \n",
    "            print(f\"Encrypted mappings loaded from: {filepath}\")\n",
    "            return True\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Encrypted mappings file not found: {filepath}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"Load error: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def decrypt_mappings_with_password(self, password):\n",
    "        \"\"\"Decrypt mappings using provided password\"\"\"\n",
    "        if self.encrypted_mappings is None:\n",
    "            print(\"No encrypted mappings loaded!\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Regenerate key from password\n",
    "            password_bytes = password.encode('utf-8')\n",
    "            salt = b'pii_masking_salt_2024'\n",
    "            key = hashlib.pbkdf2_hmac('sha256', password_bytes, salt, 100000)\n",
    "            fernet_key = base64.urlsafe_b64encode(key)\n",
    "            temp_fernet = Fernet(fernet_key)\n",
    "            \n",
    "            # Decrypt the data\n",
    "            encrypted_data = base64.b64decode(self.encrypted_mappings['encrypted_data'])\n",
    "            decrypted_bytes = temp_fernet.decrypt(encrypted_data)\n",
    "            decrypted_json = decrypted_bytes.decode('utf-8')\n",
    "            \n",
    "            mappings = json.loads(decrypted_json)\n",
    "            print(\"Mappings decrypted successfully\")\n",
    "            return mappings\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Decryption failed: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def reverse_mappings(self, mappings_dict):\n",
    "        \"\"\"Create reverse mappings for data recovery\"\"\"\n",
    "        reverse_mappings = {}\n",
    "        \n",
    "        for category, mapping in mappings_dict.items():\n",
    "            reverse_mappings[category] = {}\n",
    "            for original, masked in mapping.items():\n",
    "                reverse_mappings[category][str(masked)] = original\n",
    "        \n",
    "        return reverse_mappings\n",
    "\n",
    "# Initialize encryption system\n",
    "encryption_system = PIIEncryptionSystem()\n",
    "print(\"Encryption system initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f87a6a-9e2b-4e2c-b59a-172472771047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_analyze_dataset(file_path='../data/generated_data.csv'):\n",
    "    \"\"\"Load dataset and perform initial analysis\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        print(f\"Dataset loaded successfully!\")\n",
    "        print(f\"Shape: {df.shape}\")\n",
    "        print(f\"Columns: {list(df.columns)}\")\n",
    "        print(\"\\nFirst 3 rows preview:\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for i, row in df.head(3).iterrows():\n",
    "            print(f\"\\nRow {i+1}:\")\n",
    "            for col in df.columns:\n",
    "                print(f\"  {col}: {row[col]}\")\n",
    "        \n",
    "        print(f\"\\nMissing values per column:\")\n",
    "        missing = df.isnull().sum()\n",
    "        for col, count in missing.items():\n",
    "            if count > 0:\n",
    "                print(f\"  {col}: {count}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {file_path} not found.\")\n",
    "        print(\"Please make sure your dataset is in the correct location.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73d7fa-a582-49ff-84cc-b97ec5649680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze the dataset\n",
    "df = load_and_analyze_dataset()\n",
    "\n",
    "if df is not None:\n",
    "    # Detect PII columns\n",
    "    detected_pii = detector.detect_pii_columns(df)\n",
    "    detector.validate_pii_detection(df, detected_pii)\n",
    "    \n",
    "    # Save detected PII info\n",
    "    pii_config_path = f'../config/detected_pii_{SESSION_ID}.json'\n",
    "    with open(pii_config_path, 'w') as f:\n",
    "        json.dump(detected_pii, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nDetected {len(detected_pii)} PII columns out of {len(df.columns)} total columns.\")\n",
    "    print(f\"PII detection saved to: {pii_config_path}\")\n",
    "else:\n",
    "    print(\"Please check your dataset file and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c16258-2270-4f01-b240-df9627e12070",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedBulletproofPIIMasker:\n",
    "    \"\"\"Enhanced masker with full reversibility for all PII types\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mappings = {\n",
    "            'names': {},\n",
    "            'addresses': {},\n",
    "            'emails': {},\n",
    "            'phones': {},\n",
    "            'organizations': {},\n",
    "            'phone_numbers': {},\n",
    "            'ssn_numbers': {},\n",
    "            'license_numbers': {},\n",
    "            'vehicle_ids': {},\n",
    "            'device_serials': {},\n",
    "            'medical_records': {},\n",
    "            'ip_addresses': {},\n",
    "            'dates': {}\n",
    "        }\n",
    "        self.fake_domains = [\"gmail.com\", \"yahoo.com\", \"hotmail.com\", \"outlook.com\", \"example.com\"]\n",
    "    \n",
    "    def mask_name_bulletproof(self, original_name):\n",
    "        \"\"\"BULLETPROOF name masking - character by character\"\"\"\n",
    "        if pd.isna(original_name) or str(original_name).strip() == '':\n",
    "            return original_name\n",
    "            \n",
    "        original_str = str(original_name).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['names']:\n",
    "            return self.mappings['names'][original_str]\n",
    "        \n",
    "        fake_name = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char == ' ':\n",
    "                fake_name += ' '\n",
    "            elif i == 0 or original_str[i-1] == ' ':\n",
    "                fake_name += random.choice(string.ascii_uppercase)\n",
    "            else:\n",
    "                fake_name += random.choice(string.ascii_lowercase)\n",
    "        \n",
    "        assert len(fake_name) == target_length, f\"Name length ERROR: {len(fake_name)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['names'][original_str] = fake_name\n",
    "        return fake_name\n",
    "    \n",
    "    def mask_address_bulletproof(self, original_address):\n",
    "        \"\"\"BULLETPROOF address masking - character by character\"\"\"\n",
    "        if pd.isna(original_address) or str(original_address).strip() == '':\n",
    "            return original_address\n",
    "            \n",
    "        original_str = str(original_address).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['addresses']:\n",
    "            return self.mappings['addresses'][original_str]\n",
    "        \n",
    "        fake_address = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char == ' ':\n",
    "                fake_address += ' '\n",
    "            elif char.isdigit():\n",
    "                fake_address += random.choice(string.digits)\n",
    "            elif char.isalpha():\n",
    "                fake_address += random.choice(string.ascii_letters)\n",
    "            else:\n",
    "                fake_address += char\n",
    "        \n",
    "        assert len(fake_address) == target_length, f\"Address length ERROR: {len(fake_address)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['addresses'][original_str] = fake_address\n",
    "        return fake_address\n",
    "    \n",
    "    def mask_email_bulletproof(self, original_email):\n",
    "        \"\"\"BULLETPROOF email masking - preserving @ and . positions\"\"\"\n",
    "        if pd.isna(original_email) or str(original_email).strip() == '':\n",
    "            return original_email\n",
    "            \n",
    "        original_str = str(original_email).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['emails']:\n",
    "            return self.mappings['emails'][original_str]\n",
    "        \n",
    "        fake_email = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char in '@.':\n",
    "                fake_email += char\n",
    "            elif char.isalpha():\n",
    "                fake_email += random.choice(string.ascii_lowercase)\n",
    "            elif char.isdigit():\n",
    "                fake_email += random.choice(string.digits)\n",
    "            else:\n",
    "                fake_email += char\n",
    "        \n",
    "        assert len(fake_email) == target_length, f\"Email length ERROR: {len(fake_email)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['emails'][original_str] = fake_email\n",
    "        return fake_email\n",
    "    \n",
    "    def mask_phone_bulletproof(self, original_phone):\n",
    "        \"\"\"BULLETPROOF phone masking with format preservation and mapping\"\"\"\n",
    "        if pd.isna(original_phone) or str(original_phone).strip() == '':\n",
    "            return original_phone\n",
    "            \n",
    "        original_str = str(original_phone).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['phone_numbers']:\n",
    "            return self.mappings['phone_numbers'][original_str]\n",
    "        \n",
    "        fake_phone = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char.isdigit():\n",
    "                seed_value = hash(original_str + str(i)) % 10\n",
    "                fake_phone += str(seed_value)\n",
    "            else:\n",
    "                fake_phone += char\n",
    "        \n",
    "        assert len(fake_phone) == target_length, f\"Phone length ERROR: {len(fake_phone)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['phone_numbers'][original_str] = fake_phone\n",
    "        return fake_phone\n",
    "    \n",
    "    def mask_ssn_bulletproof(self, original_ssn):\n",
    "        \"\"\"BULLETPROOF SSN masking with format preservation and mapping\"\"\"\n",
    "        if pd.isna(original_ssn) or str(original_ssn).strip() == '':\n",
    "            return original_ssn\n",
    "            \n",
    "        original_str = str(original_ssn).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['ssn_numbers']:\n",
    "            return self.mappings['ssn_numbers'][original_str]\n",
    "        \n",
    "        fake_ssn = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char.isdigit():\n",
    "                seed_value = hash(original_str + str(i)) % 10\n",
    "                fake_ssn += str(seed_value)\n",
    "            elif char == '-':\n",
    "                fake_ssn += '-'\n",
    "            else:\n",
    "                fake_ssn += random.choice(string.ascii_lowercase)\n",
    "        \n",
    "        assert len(fake_ssn) == target_length, f\"SSN length ERROR: {len(fake_ssn)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['ssn_numbers'][original_str] = fake_ssn\n",
    "        return fake_ssn\n",
    "    \n",
    "    def mask_license_bulletproof(self, original_license):\n",
    "        \"\"\"BULLETPROOF license number masking\"\"\"\n",
    "        if pd.isna(original_license) or str(original_license).strip() == '':\n",
    "            return original_license\n",
    "            \n",
    "        original_str = str(original_license).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['license_numbers']:\n",
    "            return self.mappings['license_numbers'][original_str]\n",
    "        \n",
    "        fake_license = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char.isdigit():\n",
    "                seed_value = hash(original_str + str(i)) % 10\n",
    "                fake_license += str(seed_value)\n",
    "            elif char.isalpha():\n",
    "                if char.isupper():\n",
    "                    fake_license += random.choice(string.ascii_uppercase)\n",
    "                else:\n",
    "                    fake_license += random.choice(string.ascii_lowercase)\n",
    "            else:\n",
    "                fake_license += char\n",
    "        \n",
    "        assert len(fake_license) == target_length, f\"License length ERROR: {len(fake_license)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['license_numbers'][original_str] = fake_license\n",
    "        return fake_license\n",
    "    \n",
    "    def mask_vehicle_id_bulletproof(self, original_vehicle_id):\n",
    "        \"\"\"BULLETPROOF vehicle ID masking\"\"\"\n",
    "        if pd.isna(original_vehicle_id) or str(original_vehicle_id).strip() == '':\n",
    "            return original_vehicle_id\n",
    "            \n",
    "        original_str = str(original_vehicle_id).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['vehicle_ids']:\n",
    "            return self.mappings['vehicle_ids'][original_str]\n",
    "        \n",
    "        fake_vehicle_id = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char.isdigit():\n",
    "                seed_value = hash(original_str + str(i)) % 10\n",
    "                fake_vehicle_id += str(seed_value)\n",
    "            elif char.isalpha():\n",
    "                if char.isupper():\n",
    "                    fake_vehicle_id += random.choice(string.ascii_uppercase)\n",
    "                else:\n",
    "                    fake_vehicle_id += random.choice(string.ascii_lowercase)\n",
    "            else:\n",
    "                fake_vehicle_id += char\n",
    "        \n",
    "        assert len(fake_vehicle_id) == target_length, f\"Vehicle ID length ERROR: {len(fake_vehicle_id)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['vehicle_ids'][original_str] = fake_vehicle_id\n",
    "        return fake_vehicle_id\n",
    "    \n",
    "    def mask_device_serial_bulletproof(self, original_serial):\n",
    "        \"\"\"BULLETPROOF device serial masking\"\"\"\n",
    "        if pd.isna(original_serial) or str(original_serial).strip() == '':\n",
    "            return original_serial\n",
    "            \n",
    "        original_str = str(original_serial).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['device_serials']:\n",
    "            return self.mappings['device_serials'][original_str]\n",
    "        \n",
    "        fake_serial = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char.isdigit():\n",
    "                seed_value = hash(original_str + str(i)) % 10\n",
    "                fake_serial += str(seed_value)\n",
    "            elif char.isalpha():\n",
    "                if char.isupper():\n",
    "                    fake_serial += random.choice(string.ascii_uppercase)\n",
    "                else:\n",
    "                    fake_serial += random.choice(string.ascii_lowercase)\n",
    "            else:\n",
    "                fake_serial += char\n",
    "        \n",
    "        assert len(fake_serial) == target_length, f\"Serial length ERROR: {len(fake_serial)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['device_serials'][original_str] = fake_serial\n",
    "        return fake_serial\n",
    "    \n",
    "    def mask_ip_address_bulletproof(self, original_ip):\n",
    "        \"\"\"BULLETPROOF IP address masking\"\"\"\n",
    "        if pd.isna(original_ip) or str(original_ip).strip() == '':\n",
    "            return original_ip\n",
    "            \n",
    "        original_str = str(original_ip).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['ip_addresses']:\n",
    "            return self.mappings['ip_addresses'][original_str]\n",
    "        \n",
    "        if '.' in original_str and ':' not in original_str:\n",
    "            # IPv4 format\n",
    "            parts = original_str.split('.')\n",
    "            fake_parts = []\n",
    "            for part in parts:\n",
    "                fake_part = str(random.randint(1, 254))\n",
    "                fake_parts.append(fake_part)\n",
    "            fake_ip = '.'.join(fake_parts)\n",
    "            \n",
    "        elif ':' in original_str:\n",
    "            # IPv6 format - preserve structure\n",
    "            fake_ip = ''\n",
    "            for i in range(target_length):\n",
    "                char = original_str[i]\n",
    "                if char in '0123456789abcdefABCDEF':\n",
    "                    fake_ip += random.choice('0123456789abcdef')\n",
    "                else:\n",
    "                    fake_ip += char\n",
    "        else:\n",
    "            # Unknown format - character by character\n",
    "            fake_ip = ''\n",
    "            for i in range(target_length):\n",
    "                char = original_str[i]\n",
    "                if char.isdigit():\n",
    "                    fake_ip += str(random.randint(0, 9))\n",
    "                elif char.isalpha():\n",
    "                    fake_ip += random.choice(string.ascii_lowercase)\n",
    "                else:\n",
    "                    fake_ip += char\n",
    "        \n",
    "        # Ensure exact length for non-standard formats\n",
    "        if len(fake_ip) != target_length:\n",
    "            fake_ip = fake_ip[:target_length] if len(fake_ip) > target_length else fake_ip.ljust(target_length, '0')\n",
    "        \n",
    "        assert len(fake_ip) == target_length, f\"IP length ERROR: {len(fake_ip)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['ip_addresses'][original_str] = fake_ip\n",
    "        return fake_ip\n",
    "    \n",
    "    def mask_date_bulletproof(self, original_date):\n",
    "        \"\"\"BULLETPROOF date masking preserving exact format\"\"\"\n",
    "        if pd.isna(original_date) or str(original_date).strip() == '':\n",
    "            return original_date\n",
    "            \n",
    "        original_str = str(original_date).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['dates']:\n",
    "            return self.mappings['dates'][original_str]\n",
    "        \n",
    "        fake_date = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char.isdigit():\n",
    "                fake_date += random.choice(string.digits)\n",
    "            else:\n",
    "                fake_date += char\n",
    "        \n",
    "        assert len(fake_date) == target_length, f\"Date length ERROR: {len(fake_date)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['dates'][original_str] = fake_date\n",
    "        return fake_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be77a0f2-d8b9-4e95-aabf-d931a744ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the enhanced masker\n",
    "enhanced_masker = EnhancedBulletproofPIIMasker()\n",
    "print(\"Enhanced Bulletproof PII Masker initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69b958e-4714-4af9-9acb-59a78c862909",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullReversibleMaskingPipeline:\n",
    "    \"\"\"Enhanced pipeline with full reversibility for all PII types\"\"\"\n",
    "    \n",
    "    def __init__(self, enhanced_masker, detected_pii):\n",
    "        self.masker = enhanced_masker\n",
    "        self.detected_pii = detected_pii\n",
    "        \n",
    "        # Column maskers mapping\n",
    "        self.column_maskers = {\n",
    "            'full_name': self.masker.mask_name_bulletproof,\n",
    "            'doctor_name': self.masker.mask_name_bulletproof,\n",
    "            'address_street': self.masker.mask_address_bulletproof,\n",
    "            'address_city': self.masker.mask_address_bulletproof,\n",
    "            'address_zip': self.masker.mask_address_bulletproof,\n",
    "            'date_of_birth': self.masker.mask_date_bulletproof,\n",
    "            'admission_date': self.masker.mask_date_bulletproof,\n",
    "            'discharge_date': self.masker.mask_date_bulletproof,\n",
    "            'phone_number': self.masker.mask_phone_bulletproof,\n",
    "            'email_address': self.masker.mask_email_bulletproof,\n",
    "            'ssn': self.masker.mask_ssn_bulletproof,\n",
    "            'license_number': self.masker.mask_license_bulletproof,\n",
    "            'vehicle_id': self.masker.mask_vehicle_id_bulletproof,\n",
    "            'device_serial_number': self.masker.mask_device_serial_bulletproof,\n",
    "            'ip_address': self.masker.mask_ip_address_bulletproof,\n",
    "            'hospital_name': self.masker.mask_name_bulletproof,\n",
    "            'insurance_provider': self.masker.mask_name_bulletproof\n",
    "        }\n",
    "    \n",
    "    def mask_dataframe(self, df):\n",
    "        \"\"\"Apply bulletproof masking to the entire dataframe\"\"\"\n",
    "        masked_df = df.copy()\n",
    "        masking_report = {}\n",
    "        \n",
    "        print(\"Starting BULLETPROOF masking process...\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for column in df.columns:\n",
    "            if column in self.column_maskers:\n",
    "                print(f\"Masking column: {column}\")\n",
    "                \n",
    "                mask_function = self.column_maskers[column]\n",
    "                \n",
    "                try:\n",
    "                    masked_values = []\n",
    "                    original_values = df[column].tolist()\n",
    "                    \n",
    "                    for value in original_values:\n",
    "                        masked_value = mask_function(value)\n",
    "                        masked_values.append(masked_value)\n",
    "                    \n",
    "                    masked_df[column] = masked_values\n",
    "                    \n",
    "                    length_errors = 0\n",
    "                    for orig, masked in zip(original_values, masked_values):\n",
    "                        if not pd.isna(orig) and not pd.isna(masked):\n",
    "                            if len(str(orig).strip()) != len(str(masked).strip()):\n",
    "                                length_errors += 1\n",
    "                    \n",
    "                    non_null_original = df[column].dropna().head(3).tolist()\n",
    "                    non_null_masked = pd.Series(masked_values).dropna().head(3).tolist()\n",
    "                    \n",
    "                    masking_report[column] = {\n",
    "                        'status': 'success',\n",
    "                        'total_rows': len(df),\n",
    "                        'length_errors': length_errors,\n",
    "                        'sample_original': non_null_original,\n",
    "                        'sample_masked': non_null_masked\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"  Successfully masked {len(masked_values)} values\")\n",
    "                    if length_errors > 0:\n",
    "                        print(f\"  {length_errors} length mismatches detected\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  Error masking column {column}: {str(e)}\")\n",
    "                    masking_report[column] = {\n",
    "                        'status': 'error',\n",
    "                        'error': str(e)\n",
    "                    }\n",
    "            else:\n",
    "                print(f\"Keeping original: {column} (not PII)\")\n",
    "                masking_report[column] = {'status': 'unchanged'}\n",
    "        \n",
    "        print(f\"\\nBulletproof masking completed!\")\n",
    "        return masked_df, masking_report\n",
    "    \n",
    "    def display_masking_report(self, masking_report):\n",
    "        \"\"\"Display detailed masking report\"\"\"\n",
    "        print(\"\\nBulletproof Masking Report:\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        total_length_errors = 0\n",
    "        \n",
    "        for column, report in masking_report.items():\n",
    "            print(f\"\\nColumn: {column}\")\n",
    "            print(f\"Status: {report['status']}\")\n",
    "            \n",
    "            if report['status'] == 'success':\n",
    "                length_errors = report.get('length_errors', 0)\n",
    "                total_length_errors += length_errors\n",
    "                \n",
    "                print(f\"Length errors: {length_errors}\")\n",
    "                print(f\"Original samples: {report['sample_original']}\")\n",
    "                print(f\"Masked samples:   {report['sample_masked']}\")\n",
    "            elif report['status'] == 'error':\n",
    "                print(f\"Error: {report['error']}\")\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        if total_length_errors == 0:\n",
    "            print(\"PERFECT! No length preservation errors!\")\n",
    "        else:\n",
    "            print(f\"Total length errors across all columns: {total_length_errors}\")\n",
    "\n",
    "print(\"Masking Pipeline class created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f906b91-0b05-44eb-83c9-a029397c2dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals() and df is not None and 'detected_pii' in locals():\n",
    "    print(\"Applying Enhanced Masking with Encryption...\")\n",
    "    \n",
    "    # Generate encryption key from user password\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ENCRYPTION SETUP\")\n",
    "    print(\"=\"*60)\n",
    "    encryption_system.generate_encryption_key()\n",
    "    \n",
    "    # Create masking pipeline\n",
    "    pipeline = FullReversibleMaskingPipeline(enhanced_masker, detected_pii)\n",
    "    \n",
    "    # Step 3: Apply masking\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"APPLYING MASKING\")\n",
    "    print(\"=\"*60)\n",
    "    masked_df, masking_report = pipeline.mask_dataframe(df)\n",
    "    \n",
    "    # Display masking report\n",
    "    pipeline.display_masking_report(masking_report)\n",
    "    \n",
    "    # Step 5: Save masked dataset to results folder\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    masked_filename = f\"masked_dataset_{SESSION_ID}_{timestamp}.csv\"\n",
    "    masked_filepath = os.path.join('../results', masked_filename)\n",
    "    \n",
    "    masked_df.to_csv(masked_filepath, index=False)\n",
    "    print(f\"\\n✅ Masked dataset saved to: {masked_filepath}\")\n",
    "    \n",
    "    # Encrypt and save mappings\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ENCRYPTING MAPPINGS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get all mappings from the masker\n",
    "    all_mappings = enhanced_masker.mappings\n",
    "    \n",
    "    # Display mapping statistics\n",
    "    print(\"Mapping categories created:\")\n",
    "    for category, mappings in all_mappings.items():\n",
    "        if mappings:\n",
    "            print(f\"  {category}: {len(mappings)} mappings\")\n",
    "    \n",
    "    # Encrypt the mappings\n",
    "    encryption_success = encryption_system.encrypt_mappings(all_mappings)\n",
    "    \n",
    "    if encryption_success:\n",
    "        # Save encrypted mappings\n",
    "        encrypted_mappings_path = f'../config/encrypted_mappings_{SESSION_ID}.json'\n",
    "        encryption_system.save_encrypted_mappings(encrypted_mappings_path)\n",
    "        \n",
    "        # Save key info (not the actual key)\n",
    "        key_info_path = f'../config/key_info_{SESSION_ID}.json'\n",
    "        encryption_system.save_key_info(key_info_path)\n",
    "        \n",
    "        print(f\"✅ Encrypted mappings saved to: {encrypted_mappings_path}\")\n",
    "        print(f\"✅ Key info saved to: {key_info_path}\")\n",
    "        \n",
    "        # Save session info for easy reversal\n",
    "        session_info = {\n",
    "            'session_id': SESSION_ID,\n",
    "            'timestamp': timestamp,\n",
    "            'original_dataset_shape': df.shape,\n",
    "            'masked_dataset_path': masked_filepath,\n",
    "            'encrypted_mappings_path': encrypted_mappings_path,\n",
    "            'key_info_path': key_info_path,\n",
    "            'pii_columns_detected': len(detected_pii),\n",
    "            'total_columns': len(df.columns),\n",
    "            'note': 'Use this session info to reverse the dataset with the correct encryption password'\n",
    "        }\n",
    "        \n",
    "        session_info_path = f'../config/session_info_{SESSION_ID}.json'\n",
    "        with open(session_info_path, 'w') as f:\n",
    "            json.dump(session_info, f, indent=2)\n",
    "        \n",
    "        print(f\"✅ Session info saved to: {session_info_path}\")\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"MASKING COMPLETE!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"📁 Session ID: {SESSION_ID}\")\n",
    "        print(f\"📁 Masked dataset: {masked_filepath}\")\n",
    "        print(f\"🔒 Encrypted mappings: {encrypted_mappings_path}\")\n",
    "        print(f\"📋 Session info: {session_info_path}\")\n",
    "        print(f\"\\n💡 To reverse this dataset, use the reversal function with:\")\n",
    "        print(f\"   - Session ID: {SESSION_ID}\")\n",
    "        print(f\"   - Your encryption password\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ Failed to encrypt mappings!\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ Please run the previous cells to load data and detect PII first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ff77a6-37eb-4e81-9ea8-ec370c115595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_masked_dataset_enhanced(session_id=None, masked_csv_path=None):\n",
    "    \"\"\"\n",
    "    ENHANCED DATA REVERSAL with password protection and session management\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"ENHANCED DATA REVERSAL SYSTEM\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get session ID if not provided\n",
    "    if session_id is None:\n",
    "        print(\"Available sessions:\")\n",
    "        config_files = [f for f in os.listdir('../config') if f.startswith('session_info_')]\n",
    "        if not config_files:\n",
    "            print(\"No sessions found!\")\n",
    "            return None, None\n",
    "        \n",
    "        for i, file in enumerate(config_files):\n",
    "            session_id_from_file = file.replace('session_info_', '').replace('.json', '')\n",
    "            with open(f'../config/{file}', 'r') as f:\n",
    "                info = json.load(f)\n",
    "            print(f\"{i+1}. Session ID: {session_id_from_file} ({info['timestamp']})\")\n",
    "        \n",
    "        choice = input(\"\\nEnter session number or session ID: \").strip()\n",
    "        \n",
    "        if choice.isdigit():\n",
    "            choice_idx = int(choice) - 1\n",
    "            if 0 <= choice_idx < len(config_files):\n",
    "                session_id = config_files[choice_idx].replace('session_info_', '').replace('.json', '')\n",
    "            else:\n",
    "                print(\"Invalid choice!\")\n",
    "                return None, None\n",
    "        else:\n",
    "            session_id = choice\n",
    "    \n",
    "    print(f\"\\nUsing Session ID: {session_id}\")\n",
    "    \n",
    "    # Load session info\n",
    "    session_info_path = f'../config/session_info_{session_id}.json'\n",
    "    try:\n",
    "        with open(session_info_path, 'r') as f:\n",
    "            session_info = json.load(f)\n",
    "        print(f\"✅ Session info loaded\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ Session info not found: {session_info_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Get masked dataset path\n",
    "    if masked_csv_path is None:\n",
    "        masked_csv_path = session_info['masked_dataset_path']\n",
    "    \n",
    "    print(f\"📁 Masked dataset: {masked_csv_path}\")\n",
    "    \n",
    "    # Load masked data\n",
    "    try:\n",
    "        masked_df = pd.read_csv(masked_csv_path)\n",
    "        print(f\"✅ Loaded masked dataset: {masked_df.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ Masked dataset not found: {masked_csv_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Load encrypted mappings\n",
    "    encrypted_mappings_path = session_info['encrypted_mappings_path']\n",
    "    temp_encryption = PIIEncryptionSystem()\n",
    "    \n",
    "    mappings_loaded = temp_encryption.load_encrypted_mappings(encrypted_mappings_path)\n",
    "    if not mappings_loaded:\n",
    "        print(f\"❌ Encrypted mappings not found: {encrypted_mappings_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Get password and decrypt\n",
    "    print(f\"\\n🔒 DECRYPTION REQUIRED\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    max_attempts = 3\n",
    "    for attempt in range(max_attempts):\n",
    "        password = getpass.getpass(f\"Enter encryption password (attempt {attempt+1}/{max_attempts}): \")\n",
    "        \n",
    "        decrypted_mappings = temp_encryption.decrypt_mappings_with_password(password)\n",
    "        \n",
    "        if decrypted_mappings is not None:\n",
    "            print(\"✅ Password correct! Mappings decrypted successfully\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"❌ Incorrect password! {max_attempts - attempt - 1} attempts remaining\")\n",
    "            if attempt == max_attempts - 1:\n",
    "                print(\"❌ Maximum attempts reached. Reversal failed.\")\n",
    "                return None, None\n",
    "    \n",
    "    # Create reverse mappings\n",
    "    reverse_mappings = temp_encryption.reverse_mappings(decrypted_mappings)\n",
    "    \n",
    "    print(f\"\\n📊 Available mapping categories:\")\n",
    "    for category, mappings in reverse_mappings.items():\n",
    "        if mappings:\n",
    "            print(f\"  {category}: {len(mappings)} mappings\")\n",
    "    \n",
    "    # Enhanced column to category mapping\n",
    "    column_categories = {\n",
    "        'full_name': 'names',\n",
    "        'doctor_name': 'names',\n",
    "        'address_street': 'addresses', \n",
    "        'address_city': 'addresses',\n",
    "        'address_zip': 'addresses',\n",
    "        'email_address': 'emails',\n",
    "        'phone_number': 'phone_numbers',\n",
    "        'ssn': 'ssn_numbers',\n",
    "        'license_number': 'license_numbers',\n",
    "        'vehicle_id': 'vehicle_ids',\n",
    "        'device_serial_number': 'device_serials',\n",
    "        'ip_address': 'ip_addresses',\n",
    "        'hospital_name': 'names',\n",
    "        'insurance_provider': 'names',\n",
    "        'date_of_birth': 'dates',\n",
    "        'admission_date': 'dates',\n",
    "        'discharge_date': 'dates'\n",
    "    }\n",
    "    \n",
    "    # Apply enhanced reversal\n",
    "    print(f\"\\n🔄 REVERSING DATA\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    recovered_df = masked_df.copy()\n",
    "    reversal_stats = {}\n",
    "    \n",
    "    for column in masked_df.columns:\n",
    "        if column in column_categories:\n",
    "            category = column_categories[column]\n",
    "            \n",
    "            if category in reverse_mappings and reverse_mappings[category]:\n",
    "                print(f\"  Reversing {column} ({category})...\")\n",
    "                \n",
    "                recovered_values = []\n",
    "                successful_reversals = 0\n",
    "                \n",
    "                for value in masked_df[column]:\n",
    "                    if pd.isna(value):\n",
    "                        recovered_values.append(value)\n",
    "                    else:\n",
    "                        value_str = str(value)\n",
    "                        if value_str in reverse_mappings[category]:\n",
    "                            original = reverse_mappings[category][value_str]\n",
    "                            recovered_values.append(original)\n",
    "                            successful_reversals += 1\n",
    "                        else:\n",
    "                            recovered_values.append(value)\n",
    "                \n",
    "                recovered_df[column] = recovered_values\n",
    "                success_rate = (successful_reversals / len(masked_df)) * 100\n",
    "                reversal_stats[column] = {\n",
    "                    'successful': successful_reversals,\n",
    "                    'total': len(masked_df),\n",
    "                    'success_rate': success_rate\n",
    "                }\n",
    "                \n",
    "                print(f\"    ✅ Recovered {successful_reversals}/{len(masked_df)} values ({success_rate:.1f}%)\")\n",
    "            else:\n",
    "                print(f\"    ⚠️ No mappings found for {column}\")\n",
    "                reversal_stats[column] = {'status': 'no_mappings'}\n",
    "        else:\n",
    "            reversal_stats[column] = {'status': 'not_pii'}\n",
    "    \n",
    "    # Save recovered data to reversed_datasets folder\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    recovered_filename = f\"recovered_dataset_{session_id}_{timestamp}.csv\"\n",
    "    recovered_filepath = os.path.join('../results/reversed_datasets', recovered_filename)\n",
    "    \n",
    "    recovered_df.to_csv(recovered_filepath, index=False)\n",
    "    \n",
    "    # Create recovery report\n",
    "    recovery_report = {\n",
    "        'session_id': session_id,\n",
    "        'recovery_timestamp': timestamp,\n",
    "        'original_masked_file': masked_csv_path,\n",
    "        'recovered_file': recovered_filepath,\n",
    "        'reversal_stats': reversal_stats,\n",
    "        'total_columns': len(masked_df.columns),\n",
    "        'pii_columns_processed': len([col for col in reversal_stats if 'success_rate' in reversal_stats[col]]),\n",
    "        'perfect_reversals': len([col for col in reversal_stats if reversal_stats[col].get('success_rate') == 100])\n",
    "    }\n",
    "    \n",
    "    recovery_report_path = os.path.join('../results/reversed_datasets', f'recovery_report_{session_id}_{timestamp}.json')\n",
    "    with open(recovery_report_path, 'w') as f:\n",
    "        json.dump(recovery_report, f, indent=2)\n",
    "    \n",
    "    total_pii_columns = recovery_report['pii_columns_processed']\n",
    "    perfect_columns = recovery_report['perfect_reversals']\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"ENHANCED REVERSAL COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"✅ Perfect reversals: {perfect_columns}/{total_pii_columns} PII columns\")\n",
    "    print(f\"📁 Recovered dataset: {recovered_filepath}\")\n",
    "    print(f\"📋 Recovery report: {recovery_report_path}\")\n",
    "    print(f\"🔒 Session ID: {session_id}\")\n",
    "    \n",
    "    return recovered_df, reversal_stats\n",
    "\n",
    "print(\"Enhanced Reversal Function created successfully!\")\n",
    "print(\"\\n💡 Usage:\")\n",
    "print(\"   reverse_masked_dataset_enhanced()  # Interactive mode\")\n",
    "print(\"   reverse_masked_dataset_enhanced('your_session_id')  # Direct mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b411678-555b-4c46-bd94-2701fda3722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the reversal function\n",
    "print(\"Testing Reversal Function...\")\n",
    "print(\"This will ask for your encryption password to reverse the masked data\")\n",
    "\n",
    "# Run the enhanced reversal function\n",
    "recovered_df, reversal_stats = reverse_masked_dataset_enhanced()\n",
    "\n",
    "if recovered_df is not None:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"REVERSAL TEST RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Display some comparison between original and recovered\n",
    "    if 'df' in locals():\n",
    "        print(\"Comparing original vs recovered data (first 3 rows):\")\n",
    "        print(\"\\nOriginal data sample:\")\n",
    "        for col in df.columns[:3]:  # Show first 3 columns\n",
    "            print(f\"{col}: {df[col].head(3).tolist()}\")\n",
    "        \n",
    "        print(\"\\nRecovered data sample:\")\n",
    "        for col in recovered_df.columns[:3]:  # Show first 3 columns\n",
    "            print(f\"{col}: {recovered_df[col].head(3).tolist()}\")\n",
    "    \n",
    "    print(\"\\n✅ Reversal test completed successfully!\")\n",
    "else:\n",
    "    print(\"❌ Reversal test failed!\")\n",
    "\n",
    "print(\"Reversal test cell ready (uncomment to run)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e6302f-98bd-4c05-8ac2-e2e9d798847d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
