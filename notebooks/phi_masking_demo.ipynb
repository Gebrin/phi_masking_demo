{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae9453f1-ec62-4f89-9d97-357dc8ff8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from cryptography.fernet import Fernet\n",
    "import string\n",
    "import base64\n",
    "import hashlib\n",
    "import getpass\n",
    "import uuid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fda24a42-1418-4da0-be92-fc8b0afc8860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\gibso\\PycharmProjects\\phi_masking_demo\\notebooks\n",
      "Directory exists: ../data\n",
      "Directory exists: ../results\n",
      "Directory exists: ../results/reversed_datasets\n",
      "Directory exists: ../config\n"
     ]
    }
   ],
   "source": [
    "def setup_directories():\n",
    "    \"\"\"Create all required directories\"\"\"\n",
    "    directories = [\n",
    "        '../data', \n",
    "        '../results', \n",
    "        '../results/reversed_datasets', \n",
    "        '../config'\n",
    "    ]\n",
    "    for directory in directories:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            print(f\"Created directory: {directory}\")\n",
    "        else:\n",
    "            print(f\"Directory exists: {directory}\")\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "setup_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f67356d-8d32-48e5-b0b0-dee134dd07f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session ID: 2ffd3559\n"
     ]
    }
   ],
   "source": [
    "SESSION_ID = str(uuid.uuid4())[:8]\n",
    "print(f\"Session ID: {SESSION_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50333312-13dd-4ca9-922f-96860363668c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PII Column Categories:\n",
      "names: ['full_name', 'doctor_name']\n",
      "addresses: ['address_street', 'address_city', 'address_zip']\n",
      "dates: ['date_of_birth', 'admission_date', 'discharge_date']\n",
      "contact: ['phone_number', 'email_address']\n",
      "identifiers: ['ssn', 'license_number', 'vehicle_id', 'device_serial_number']\n",
      "network: ['ip_address']\n",
      "organizations: ['hospital_name', 'insurance_provider']\n"
     ]
    }
   ],
   "source": [
    "PII_COLUMNS = {\n",
    "    'names': ['full_name', 'doctor_name'],\n",
    "    'addresses': ['address_street', 'address_city', 'address_zip'],\n",
    "    'dates': ['date_of_birth', 'admission_date', 'discharge_date'],\n",
    "    'contact': ['phone_number', 'email_address'],\n",
    "    'identifiers': ['ssn', 'license_number', 'vehicle_id', 'device_serial_number'],\n",
    "    'network': ['ip_address'],\n",
    "    'organizations': ['hospital_name', 'insurance_provider']\n",
    "}\n",
    "\n",
    "print(\"PII Column Categories:\")\n",
    "for category, columns in PII_COLUMNS.items():\n",
    "    print(f\"{category}: {columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b79602c-0d8c-45c2-ade7-fc61779ba5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PII Detector initialized.\n"
     ]
    }
   ],
   "source": [
    "class PIIDetector:\n",
    "    def __init__(self):\n",
    "        self.patterns = {\n",
    "            'email': r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',\n",
    "            'phone': r'(\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}(\\s*x\\d+)?)',\n",
    "            'ssn': r'\\b\\d{3}-?\\d{2}-?\\d{4}\\b',\n",
    "            'ip_v4': r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b',\n",
    "            'ip_v6': r'\\b(?:[0-9a-fA-F]{1,4}:){7}[0-9a-fA-F]{1,4}\\b',\n",
    "            'date': r'\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}',\n",
    "            'zip_code': r'\\b\\d{5}(-\\d{4})?\\b',\n",
    "        }\n",
    "        \n",
    "        self.pii_keywords = {\n",
    "            'name': ['name', 'first', 'last', 'full_name', 'doctor', 'patient'],\n",
    "            'address': ['address', 'street', 'city', 'state', 'zip', 'postal'],\n",
    "            'contact': ['phone', 'email', 'telephone', 'mobile'],\n",
    "            'id': ['id', 'ssn', 'social', 'license', 'serial', 'number'],\n",
    "            'date': ['date', 'birth', 'dob', 'admission', 'discharge'],\n",
    "            'organization': ['hospital', 'insurance', 'provider', 'company']\n",
    "        }\n",
    "    \n",
    "    def detect_pii_columns(self, df):\n",
    "        \"\"\"Detect PII columns based on column names and content patterns\"\"\"\n",
    "        pii_detected = {}\n",
    "        \n",
    "        for column in df.columns:\n",
    "            column_lower = column.lower()\n",
    "            pii_type = None\n",
    "            confidence = 0\n",
    "            \n",
    "            for pii_category, keywords in self.pii_keywords.items():\n",
    "                for keyword in keywords:\n",
    "                    if keyword in column_lower:\n",
    "                        pii_type = pii_category\n",
    "                        confidence += 0.7\n",
    "                        break\n",
    "            \n",
    "            sample_data = df[column].dropna().head(100).astype(str)\n",
    "            \n",
    "            for pattern_name, pattern in self.patterns.items():\n",
    "                matches = sample_data.str.contains(pattern, regex=True, na=False).sum()\n",
    "                match_ratio = matches / len(sample_data) if len(sample_data) > 0 else 0\n",
    "                \n",
    "                if match_ratio > 0.5:\n",
    "                    if pattern_name == 'email':\n",
    "                        pii_type = 'contact'\n",
    "                        confidence += 0.8\n",
    "                    elif pattern_name == 'phone':\n",
    "                        pii_type = 'contact'\n",
    "                        confidence += 0.8\n",
    "                    elif pattern_name in ['ip_v4', 'ip_v6']:\n",
    "                        pii_type = 'network'\n",
    "                        confidence += 0.9\n",
    "                    elif pattern_name == 'date':\n",
    "                        pii_type = 'date'\n",
    "                        confidence += 0.6\n",
    "            \n",
    "            if pii_type and confidence > 0.5:\n",
    "                pii_detected[column] = {\n",
    "                    'type': pii_type,\n",
    "                    'confidence': min(confidence, 1.0)\n",
    "                }\n",
    "        \n",
    "        return pii_detected\n",
    "    \n",
    "    def validate_pii_detection(self, df, detected_pii):\n",
    "        \"\"\"Display detection results for validation\"\"\"\n",
    "        print(\"PII Detection Results:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for column, info in detected_pii.items():\n",
    "            sample_values = df[column].dropna().head(3).tolist()\n",
    "            print(f\"Column: {column}\")\n",
    "            print(f\"  Type: {info['type']}\")\n",
    "            print(f\"  Confidence: {info['confidence']:.2f}\")\n",
    "            print(f\"  Sample values: {sample_values}\")\n",
    "            print()\n",
    "\n",
    "detector = PIIDetector()\n",
    "print(\"PII Detector initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "799ac094-4898-4816-8aa8-7ad10f76699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption system initialized\n"
     ]
    }
   ],
   "source": [
    "class PIIEncryptionSystem:\n",
    "    \"\"\"Secure encryption system for PII mappings with user-defined encryption keys\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.key = None\n",
    "        self.fernet = None\n",
    "        self.encrypted_mappings = None\n",
    "        self.user_password = None\n",
    "        \n",
    "    def generate_encryption_key(self, user_password=None):\n",
    "        \"\"\"Generate encryption key from user password\"\"\"\n",
    "        if user_password is None:\n",
    "            user_password = getpass.getpass(\"Enter encryption password for this dataset: \")\n",
    "        \n",
    "        self.user_password = user_password\n",
    "        \n",
    "        # Generate key from password using PBKDF2\n",
    "        password_bytes = user_password.encode('utf-8')\n",
    "        salt = b'pii_masking_salt_2024'  # Fixed salt for consistency\n",
    "        key = hashlib.pbkdf2_hmac('sha256', password_bytes, salt, 100000)\n",
    "        \n",
    "        # Fernet requires base64 encoded key\n",
    "        self.key = base64.urlsafe_b64encode(key)\n",
    "        self.fernet = Fernet(self.key)\n",
    "        \n",
    "        print(\"Encryption key generated from password\")\n",
    "        return True\n",
    "    \n",
    "    def save_key_info(self, filepath):\n",
    "        \"\"\"Save key generation info (not the actual key)\"\"\"\n",
    "        key_info = {\n",
    "            'session_id': SESSION_ID,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'key_generated': True,\n",
    "            'note': 'Key generated from user password'\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(key_info, f, indent=2)\n",
    "        \n",
    "        print(f\"Key info saved to: {filepath}\")\n",
    "        return True\n",
    "    \n",
    "    def encrypt_mappings(self, mappings_dict):\n",
    "        \"\"\"Encrypt the mappings dictionary\"\"\"\n",
    "        if self.fernet is None:\n",
    "            print(\"No encryption key available!\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # Convert mappings to JSON string\n",
    "            mappings_json = json.dumps(mappings_dict, indent=2)\n",
    "            mappings_bytes = mappings_json.encode('utf-8')\n",
    "            \n",
    "            # Encrypt the mappings\n",
    "            encrypted_data = self.fernet.encrypt(mappings_bytes)\n",
    "            \n",
    "            self.encrypted_mappings = {\n",
    "                'session_id': SESSION_ID,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'encrypted_data': base64.b64encode(encrypted_data).decode('utf-8')\n",
    "            }\n",
    "            \n",
    "            print(\"Mappings encrypted successfully\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Encryption error: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def save_encrypted_mappings(self, filepath):\n",
    "        \"\"\"Save encrypted mappings to file\"\"\"\n",
    "        if self.encrypted_mappings is None:\n",
    "            print(\"No encrypted mappings to save!\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            with open(filepath, 'w') as f:\n",
    "                json.dump(self.encrypted_mappings, f, indent=2)\n",
    "            \n",
    "            print(f\"Encrypted mappings saved to: {filepath}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Save error: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def load_encrypted_mappings(self, filepath):\n",
    "        \"\"\"Load encrypted mappings from file\"\"\"\n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                self.encrypted_mappings = json.load(f)\n",
    "            \n",
    "            print(f\"Encrypted mappings loaded from: {filepath}\")\n",
    "            return True\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Encrypted mappings file not found: {filepath}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"Load error: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def decrypt_mappings_with_password(self, password):\n",
    "        \"\"\"Decrypt mappings using provided password\"\"\"\n",
    "        if self.encrypted_mappings is None:\n",
    "            print(\"No encrypted mappings loaded!\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # Regenerate key from password\n",
    "            password_bytes = password.encode('utf-8')\n",
    "            salt = b'pii_masking_salt_2024'\n",
    "            key = hashlib.pbkdf2_hmac('sha256', password_bytes, salt, 100000)\n",
    "            fernet_key = base64.urlsafe_b64encode(key)\n",
    "            temp_fernet = Fernet(fernet_key)\n",
    "            \n",
    "            # Decrypt the data\n",
    "            encrypted_data = base64.b64decode(self.encrypted_mappings['encrypted_data'])\n",
    "            decrypted_bytes = temp_fernet.decrypt(encrypted_data)\n",
    "            decrypted_json = decrypted_bytes.decode('utf-8')\n",
    "            \n",
    "            mappings = json.loads(decrypted_json)\n",
    "            print(\"Mappings decrypted successfully\")\n",
    "            return mappings\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Decryption failed: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def reverse_mappings(self, mappings_dict):\n",
    "        \"\"\"Create reverse mappings for data recovery\"\"\"\n",
    "        reverse_mappings = {}\n",
    "        \n",
    "        for category, mapping in mappings_dict.items():\n",
    "            reverse_mappings[category] = {}\n",
    "            for original, masked in mapping.items():\n",
    "                reverse_mappings[category][str(masked)] = original\n",
    "        \n",
    "        return reverse_mappings\n",
    "\n",
    "# Initialize encryption system\n",
    "encryption_system = PIIEncryptionSystem()\n",
    "print(\"Encryption system initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5eed593-928f-47fe-872d-7972d685c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_analyze_dataset(file_path='../data/generated_data.csv'):\n",
    "    \"\"\"Load dataset and perform initial analysis\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        print(f\"Dataset loaded successfully!\")\n",
    "        print(f\"Shape: {df.shape}\")\n",
    "        print(f\"Columns: {list(df.columns)}\")\n",
    "        print(\"\\nFirst 3 rows preview:\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for i, row in df.head(3).iterrows():\n",
    "            print(f\"\\nRow {i+1}:\")\n",
    "            for col in df.columns:\n",
    "                print(f\"  {col}: {row[col]}\")\n",
    "        \n",
    "        print(f\"\\nMissing values per column:\")\n",
    "        missing = df.isnull().sum()\n",
    "        for col, count in missing.items():\n",
    "            if count > 0:\n",
    "                print(f\"  {col}: {count}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {file_path} not found.\")\n",
    "        print(\"Please make sure your dataset is in the correct location.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "867c8e6c-1448-41ca-b103-d0f55583f1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Shape: (5000, 23)\n",
      "Columns: ['full_name', 'address_street', 'address_city', 'address_zip', 'date_of_birth', 'admission_date', 'discharge_date', 'phone_number', 'email_address', 'ssn', 'medical_record_number', 'health_plan_id', 'account_number', 'license_number', 'vehicle_id', 'device_serial_number', 'ip_address', 'age', 'gender', 'hospital_name', 'doctor_name', 'billing_amount', 'insurance_provider']\n",
      "\n",
      "First 3 rows preview:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Row 1:\n",
      "  full_name: Irene Hudson\n",
      "  address_street: 7426 Arno Extension\n",
      "  address_city: Burdetteport\n",
      "  address_zip: 22012-0821\n",
      "  date_of_birth: 1969-03-14T16:03:18.532Z\n",
      "  admission_date: 2022-08-23T23:15:32.763Z\n",
      "  discharge_date: 2020-09-05T23:19:34.848Z\n",
      "  phone_number: 864.363.3035 x87849\n",
      "  email_address: Kiley11@gmail.com\n",
      "  ssn: tabesco\n",
      "  medical_record_number: adaugeo\n",
      "  health_plan_id: carpo\n",
      "  account_number: vorago\n",
      "  license_number: qeZMeoN7Ms\n",
      "  vehicle_id: NDYW3EFWG6JN34965\n",
      "  device_serial_number: Xh1hrTgK531h\n",
      "  ip_address: 129.135.31.111\n",
      "  age: 23\n",
      "  gender: male\n",
      "  hospital_name: Friesen LLC\n",
      "  doctor_name: Earl Welch\n",
      "  billing_amount: 14669.11647790705\n",
      "  insurance_provider: Wiegand, Weimann and Heller\n",
      "\n",
      "Row 2:\n",
      "  full_name: Archie Daugherty\n",
      "  address_street: 9686 W Pine Street\n",
      "  address_city: Littelcester\n",
      "  address_zip: 24953\n",
      "  date_of_birth: 1958-05-18T03:04:52.507Z\n",
      "  admission_date: 2023-05-22T17:41:29.702Z\n",
      "  discharge_date: 2020-06-15T03:06:28.941Z\n",
      "  phone_number: 564.262.3039 x34738\n",
      "  email_address: Colt40@yahoo.com\n",
      "  ssn: desparatus\n",
      "  medical_record_number: tum\n",
      "  health_plan_id: aeneus\n",
      "  account_number: comparo\n",
      "  license_number: 39rwOi1v8g\n",
      "  vehicle_id: 00LMPBK2DLLD75760\n",
      "  device_serial_number: sxSK3EWdQ1nz\n",
      "  ip_address: 34ad:5dca:5443:892e:acfe:4dda:dc75:026a\n",
      "  age: 19\n",
      "  gender: female\n",
      "  hospital_name: Hackett Group\n",
      "  doctor_name: Ira Mayer\n",
      "  billing_amount: 59132.03465660144\n",
      "  insurance_provider: Haag, Wyman and Paucek\n",
      "\n",
      "Row 3:\n",
      "  full_name: Bill Kuhlman\n",
      "  address_street: 64980 Wilkinson Inlet\n",
      "  address_city: North Giovannyberg\n",
      "  address_zip: 19788\n",
      "  date_of_birth: 1963-10-22T00:44:57.178Z\n",
      "  admission_date: 2022-05-21T21:43:42.320Z\n",
      "  discharge_date: 2021-03-24T14:35:35.583Z\n",
      "  phone_number: (230) 478-7562\n",
      "  email_address: Kristy_Witting85@gmail.com\n",
      "  ssn: astrum\n",
      "  medical_record_number: facilis\n",
      "  health_plan_id: aurum\n",
      "  account_number: aro\n",
      "  license_number: i5sETgPdij\n",
      "  vehicle_id: KBL13ER03TU001038\n",
      "  device_serial_number: Rn4gKu88cNxO\n",
      "  ip_address: 2fd8:b4ff:3018:4bfd:af95:2b1a:dcea:10d1\n",
      "  age: 87\n",
      "  gender: female\n",
      "  hospital_name: Spinka LLC\n",
      "  doctor_name: Mildred Osinski\n",
      "  billing_amount: 28845.42642004033\n",
      "  insurance_provider: Keebler LLC\n",
      "\n",
      "Missing values per column:\n",
      "PII Detection Results:\n",
      "--------------------------------------------------\n",
      "Column: full_name\n",
      "  Type: name\n",
      "  Confidence: 0.70\n",
      "  Sample values: ['Irene Hudson', 'Archie Daugherty', 'Bill Kuhlman']\n",
      "\n",
      "Column: address_street\n",
      "  Type: address\n",
      "  Confidence: 0.70\n",
      "  Sample values: ['7426 Arno Extension', '9686 W Pine Street', '64980 Wilkinson Inlet']\n",
      "\n",
      "Column: address_city\n",
      "  Type: address\n",
      "  Confidence: 0.70\n",
      "  Sample values: ['Burdetteport', 'Littelcester', 'North Giovannyberg']\n",
      "\n",
      "Column: address_zip\n",
      "  Type: address\n",
      "  Confidence: 0.70\n",
      "  Sample values: ['22012-0821', '24953', '19788']\n",
      "\n",
      "Column: date_of_birth\n",
      "  Type: date\n",
      "  Confidence: 1.00\n",
      "  Sample values: ['1969-03-14T16:03:18.532Z', '1958-05-18T03:04:52.507Z', '1963-10-22T00:44:57.178Z']\n",
      "\n",
      "Column: admission_date\n",
      "  Type: date\n",
      "  Confidence: 1.00\n",
      "  Sample values: ['2022-08-23T23:15:32.763Z', '2023-05-22T17:41:29.702Z', '2022-05-21T21:43:42.320Z']\n",
      "\n",
      "Column: discharge_date\n",
      "  Type: date\n",
      "  Confidence: 1.00\n",
      "  Sample values: ['2020-09-05T23:19:34.848Z', '2020-06-15T03:06:28.941Z', '2021-03-24T14:35:35.583Z']\n",
      "\n",
      "Column: phone_number\n",
      "  Type: contact\n",
      "  Confidence: 1.00\n",
      "  Sample values: ['864.363.3035 x87849', '564.262.3039 x34738', '(230) 478-7562']\n",
      "\n",
      "Column: email_address\n",
      "  Type: contact\n",
      "  Confidence: 1.00\n",
      "  Sample values: ['Kiley11@gmail.com', 'Colt40@yahoo.com', 'Kristy_Witting85@gmail.com']\n",
      "\n",
      "Column: ssn\n",
      "  Type: id\n",
      "  Confidence: 0.70\n",
      "  Sample values: ['tabesco', 'desparatus', 'astrum']\n",
      "\n",
      "Column: medical_record_number\n",
      "  Type: id\n",
      "  Confidence: 0.70\n",
      "  Sample values: ['adaugeo', 'tum', 'facilis']\n",
      "\n",
      "Column: health_plan_id\n",
      "  Type: id\n",
      "  Confidence: 0.70\n",
      "  Sample values: ['carpo', 'aeneus', 'aurum']\n",
      "\n",
      "Column: account_number\n",
      "  Type: id\n",
      "  Confidence: 0.70\n",
      "  Sample values: ['vorago', 'comparo', 'aro']\n",
      "\n",
      "Column: license_number\n",
      "  Type: id\n",
      "  Confidence: 0.70\n",
      "  Sample values: ['qeZMeoN7Ms', '39rwOi1v8g', 'i5sETgPdij']\n",
      "\n",
      "Column: vehicle_id\n",
      "  Type: id\n",
      "  Confidence: 0.70\n",
      "  Sample values: ['NDYW3EFWG6JN34965', '00LMPBK2DLLD75760', 'KBL13ER03TU001038']\n",
      "\n",
      "Column: device_serial_number\n",
      "  Type: id\n",
      "  Confidence: 0.70\n",
      "  Sample values: ['Xh1hrTgK531h', 'sxSK3EWdQ1nz', 'Rn4gKu88cNxO']\n",
      "\n",
      "Column: ip_address\n",
      "  Type: network\n",
      "  Confidence: 1.00\n",
      "  Sample values: ['129.135.31.111', '34ad:5dca:5443:892e:acfe:4dda:dc75:026a', '2fd8:b4ff:3018:4bfd:af95:2b1a:dcea:10d1']\n",
      "\n",
      "Column: hospital_name\n",
      "  Type: organization\n",
      "  Confidence: 1.00\n",
      "  Sample values: ['Friesen LLC', 'Hackett Group', 'Spinka LLC']\n",
      "\n",
      "Column: doctor_name\n",
      "  Type: name\n",
      "  Confidence: 0.70\n",
      "  Sample values: ['Earl Welch', 'Ira Mayer', 'Mildred Osinski']\n",
      "\n",
      "Column: billing_amount\n",
      "  Type: contact\n",
      "  Confidence: 0.80\n",
      "  Sample values: [14669.11647790705, 59132.03465660144, 28845.42642004033]\n",
      "\n",
      "Column: insurance_provider\n",
      "  Type: organization\n",
      "  Confidence: 1.00\n",
      "  Sample values: ['Wiegand, Weimann and Heller', 'Haag, Wyman and Paucek', 'Keebler LLC']\n",
      "\n",
      "\n",
      "Detected 21 PII columns out of 23 total columns.\n",
      "PII detection saved to: ../config/detected_pii_2ffd3559.json\n"
     ]
    }
   ],
   "source": [
    "# Load and analyze the dataset\n",
    "df = load_and_analyze_dataset()\n",
    "\n",
    "if df is not None:\n",
    "    # Detect PII columns\n",
    "    detected_pii = detector.detect_pii_columns(df)\n",
    "    detector.validate_pii_detection(df, detected_pii)\n",
    "    \n",
    "    # Save detected PII info\n",
    "    pii_config_path = f'../config/detected_pii_{SESSION_ID}.json'\n",
    "    with open(pii_config_path, 'w') as f:\n",
    "        json.dump(detected_pii, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nDetected {len(detected_pii)} PII columns out of {len(df.columns)} total columns.\")\n",
    "    print(f\"PII detection saved to: {pii_config_path}\")\n",
    "else:\n",
    "    print(\"Please check your dataset file and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "017b42a6-1cbb-432d-a338-f3582c599a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedBulletproofPIIMasker:\n",
    "    \"\"\"Enhanced masker with full reversibility for all PII types\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mappings = {\n",
    "            'names': {},\n",
    "            'addresses': {},\n",
    "            'emails': {},\n",
    "            'phones': {},\n",
    "            'organizations': {},\n",
    "            'phone_numbers': {},\n",
    "            'ssn_numbers': {},\n",
    "            'license_numbers': {},\n",
    "            'vehicle_ids': {},\n",
    "            'device_serials': {},\n",
    "            'medical_records': {},\n",
    "            'ip_addresses': {},\n",
    "            'dates': {}\n",
    "        }\n",
    "        self.fake_domains = [\"gmail.com\", \"yahoo.com\", \"hotmail.com\", \"outlook.com\", \"example.com\"]\n",
    "    \n",
    "    def mask_name_bulletproof(self, original_name):\n",
    "        \"\"\"BULLETPROOF name masking - character by character\"\"\"\n",
    "        if pd.isna(original_name) or str(original_name).strip() == '':\n",
    "            return original_name\n",
    "            \n",
    "        original_str = str(original_name).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['names']:\n",
    "            return self.mappings['names'][original_str]\n",
    "        \n",
    "        fake_name = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char == ' ':\n",
    "                fake_name += ' '\n",
    "            elif i == 0 or original_str[i-1] == ' ':\n",
    "                fake_name += random.choice(string.ascii_uppercase)\n",
    "            else:\n",
    "                fake_name += random.choice(string.ascii_lowercase)\n",
    "        \n",
    "        assert len(fake_name) == target_length, f\"Name length ERROR: {len(fake_name)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['names'][original_str] = fake_name\n",
    "        return fake_name\n",
    "    \n",
    "    def mask_address_bulletproof(self, original_address):\n",
    "        \"\"\"BULLETPROOF address masking - character by character\"\"\"\n",
    "        if pd.isna(original_address) or str(original_address).strip() == '':\n",
    "            return original_address\n",
    "            \n",
    "        original_str = str(original_address).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['addresses']:\n",
    "            return self.mappings['addresses'][original_str]\n",
    "        \n",
    "        fake_address = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char == ' ':\n",
    "                fake_address += ' '\n",
    "            elif char.isdigit():\n",
    "                fake_address += random.choice(string.digits)\n",
    "            elif char.isalpha():\n",
    "                fake_address += random.choice(string.ascii_letters)\n",
    "            else:\n",
    "                fake_address += char\n",
    "        \n",
    "        assert len(fake_address) == target_length, f\"Address length ERROR: {len(fake_address)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['addresses'][original_str] = fake_address\n",
    "        return fake_address\n",
    "    \n",
    "    def mask_email_bulletproof(self, original_email):\n",
    "        \"\"\"BULLETPROOF email masking - preserving @ and . positions\"\"\"\n",
    "        if pd.isna(original_email) or str(original_email).strip() == '':\n",
    "            return original_email\n",
    "            \n",
    "        original_str = str(original_email).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['emails']:\n",
    "            return self.mappings['emails'][original_str]\n",
    "        \n",
    "        fake_email = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char in '@.':\n",
    "                fake_email += char\n",
    "            elif char.isalpha():\n",
    "                fake_email += random.choice(string.ascii_lowercase)\n",
    "            elif char.isdigit():\n",
    "                fake_email += random.choice(string.digits)\n",
    "            else:\n",
    "                fake_email += char\n",
    "        \n",
    "        assert len(fake_email) == target_length, f\"Email length ERROR: {len(fake_email)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['emails'][original_str] = fake_email\n",
    "        return fake_email\n",
    "    \n",
    "    def mask_phone_bulletproof(self, original_phone):\n",
    "        \"\"\"BULLETPROOF phone masking with format preservation and mapping\"\"\"\n",
    "        if pd.isna(original_phone) or str(original_phone).strip() == '':\n",
    "            return original_phone\n",
    "            \n",
    "        original_str = str(original_phone).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['phone_numbers']:\n",
    "            return self.mappings['phone_numbers'][original_str]\n",
    "        \n",
    "        fake_phone = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char.isdigit():\n",
    "                seed_value = hash(original_str + str(i)) % 10\n",
    "                fake_phone += str(seed_value)\n",
    "            else:\n",
    "                fake_phone += char\n",
    "        \n",
    "        assert len(fake_phone) == target_length, f\"Phone length ERROR: {len(fake_phone)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['phone_numbers'][original_str] = fake_phone\n",
    "        return fake_phone\n",
    "    \n",
    "    def mask_ssn_bulletproof(self, original_ssn):\n",
    "        \"\"\"BULLETPROOF SSN masking with format preservation and mapping\"\"\"\n",
    "        if pd.isna(original_ssn) or str(original_ssn).strip() == '':\n",
    "            return original_ssn\n",
    "            \n",
    "        original_str = str(original_ssn).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['ssn_numbers']:\n",
    "            return self.mappings['ssn_numbers'][original_str]\n",
    "        \n",
    "        fake_ssn = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char.isdigit():\n",
    "                seed_value = hash(original_str + str(i)) % 10\n",
    "                fake_ssn += str(seed_value)\n",
    "            elif char == '-':\n",
    "                fake_ssn += '-'\n",
    "            else:\n",
    "                fake_ssn += random.choice(string.ascii_lowercase)\n",
    "        \n",
    "        assert len(fake_ssn) == target_length, f\"SSN length ERROR: {len(fake_ssn)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['ssn_numbers'][original_str] = fake_ssn\n",
    "        return fake_ssn\n",
    "    \n",
    "    def mask_license_bulletproof(self, original_license):\n",
    "        \"\"\"BULLETPROOF license number masking\"\"\"\n",
    "        if pd.isna(original_license) or str(original_license).strip() == '':\n",
    "            return original_license\n",
    "            \n",
    "        original_str = str(original_license).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['license_numbers']:\n",
    "            return self.mappings['license_numbers'][original_str]\n",
    "        \n",
    "        fake_license = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char.isdigit():\n",
    "                seed_value = hash(original_str + str(i)) % 10\n",
    "                fake_license += str(seed_value)\n",
    "            elif char.isalpha():\n",
    "                if char.isupper():\n",
    "                    fake_license += random.choice(string.ascii_uppercase)\n",
    "                else:\n",
    "                    fake_license += random.choice(string.ascii_lowercase)\n",
    "            else:\n",
    "                fake_license += char\n",
    "        \n",
    "        assert len(fake_license) == target_length, f\"License length ERROR: {len(fake_license)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['license_numbers'][original_str] = fake_license\n",
    "        return fake_license\n",
    "    \n",
    "    def mask_vehicle_id_bulletproof(self, original_vehicle_id):\n",
    "        \"\"\"BULLETPROOF vehicle ID masking\"\"\"\n",
    "        if pd.isna(original_vehicle_id) or str(original_vehicle_id).strip() == '':\n",
    "            return original_vehicle_id\n",
    "            \n",
    "        original_str = str(original_vehicle_id).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['vehicle_ids']:\n",
    "            return self.mappings['vehicle_ids'][original_str]\n",
    "        \n",
    "        fake_vehicle_id = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char.isdigit():\n",
    "                seed_value = hash(original_str + str(i)) % 10\n",
    "                fake_vehicle_id += str(seed_value)\n",
    "            elif char.isalpha():\n",
    "                if char.isupper():\n",
    "                    fake_vehicle_id += random.choice(string.ascii_uppercase)\n",
    "                else:\n",
    "                    fake_vehicle_id += random.choice(string.ascii_lowercase)\n",
    "            else:\n",
    "                fake_vehicle_id += char\n",
    "        \n",
    "        assert len(fake_vehicle_id) == target_length, f\"Vehicle ID length ERROR: {len(fake_vehicle_id)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['vehicle_ids'][original_str] = fake_vehicle_id\n",
    "        return fake_vehicle_id\n",
    "    \n",
    "    def mask_device_serial_bulletproof(self, original_serial):\n",
    "        \"\"\"BULLETPROOF device serial masking\"\"\"\n",
    "        if pd.isna(original_serial) or str(original_serial).strip() == '':\n",
    "            return original_serial\n",
    "            \n",
    "        original_str = str(original_serial).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['device_serials']:\n",
    "            return self.mappings['device_serials'][original_str]\n",
    "        \n",
    "        fake_serial = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char.isdigit():\n",
    "                seed_value = hash(original_str + str(i)) % 10\n",
    "                fake_serial += str(seed_value)\n",
    "            elif char.isalpha():\n",
    "                if char.isupper():\n",
    "                    fake_serial += random.choice(string.ascii_uppercase)\n",
    "                else:\n",
    "                    fake_serial += random.choice(string.ascii_lowercase)\n",
    "            else:\n",
    "                fake_serial += char\n",
    "        \n",
    "        assert len(fake_serial) == target_length, f\"Serial length ERROR: {len(fake_serial)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['device_serials'][original_str] = fake_serial\n",
    "        return fake_serial\n",
    "    \n",
    "    def mask_ip_address_bulletproof(self, original_ip):\n",
    "        \"\"\"BULLETPROOF IP address masking\"\"\"\n",
    "        if pd.isna(original_ip) or str(original_ip).strip() == '':\n",
    "            return original_ip\n",
    "            \n",
    "        original_str = str(original_ip).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['ip_addresses']:\n",
    "            return self.mappings['ip_addresses'][original_str]\n",
    "        \n",
    "        if '.' in original_str and ':' not in original_str:\n",
    "            # IPv4 format\n",
    "            parts = original_str.split('.')\n",
    "            fake_parts = []\n",
    "            for part in parts:\n",
    "                fake_part = str(random.randint(1, 254))\n",
    "                fake_parts.append(fake_part)\n",
    "            fake_ip = '.'.join(fake_parts)\n",
    "            \n",
    "        elif ':' in original_str:\n",
    "            # IPv6 format - preserve structure\n",
    "            fake_ip = ''\n",
    "            for i in range(target_length):\n",
    "                char = original_str[i]\n",
    "                if char in '0123456789abcdefABCDEF':\n",
    "                    fake_ip += random.choice('0123456789abcdef')\n",
    "                else:\n",
    "                    fake_ip += char\n",
    "        else:\n",
    "            # Unknown format - character by character\n",
    "            fake_ip = ''\n",
    "            for i in range(target_length):\n",
    "                char = original_str[i]\n",
    "                if char.isdigit():\n",
    "                    fake_ip += str(random.randint(0, 9))\n",
    "                elif char.isalpha():\n",
    "                    fake_ip += random.choice(string.ascii_lowercase)\n",
    "                else:\n",
    "                    fake_ip += char\n",
    "        \n",
    "        # Ensure exact length for non-standard formats\n",
    "        if len(fake_ip) != target_length:\n",
    "            fake_ip = fake_ip[:target_length] if len(fake_ip) > target_length else fake_ip.ljust(target_length, '0')\n",
    "        \n",
    "        assert len(fake_ip) == target_length, f\"IP length ERROR: {len(fake_ip)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['ip_addresses'][original_str] = fake_ip\n",
    "        return fake_ip\n",
    "    \n",
    "    def mask_date_bulletproof(self, original_date):\n",
    "        \"\"\"BULLETPROOF date masking preserving exact format\"\"\"\n",
    "        if pd.isna(original_date) or str(original_date).strip() == '':\n",
    "            return original_date\n",
    "            \n",
    "        original_str = str(original_date).strip()\n",
    "        target_length = len(original_str)\n",
    "        \n",
    "        if original_str in self.mappings['dates']:\n",
    "            return self.mappings['dates'][original_str]\n",
    "        \n",
    "        fake_date = ''\n",
    "        for i in range(target_length):\n",
    "            char = original_str[i]\n",
    "            if char.isdigit():\n",
    "                fake_date += random.choice(string.digits)\n",
    "            else:\n",
    "                fake_date += char\n",
    "        \n",
    "        assert len(fake_date) == target_length, f\"Date length ERROR: {len(fake_date)} != {target_length}\"\n",
    "        \n",
    "        self.mappings['dates'][original_str] = fake_date\n",
    "        return fake_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4521651-7ca5-434c-a63a-b75447f22cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Bulletproof PII Masker initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the enhanced masker\n",
    "enhanced_masker = EnhancedBulletproofPIIMasker()\n",
    "print(\"Enhanced Bulletproof PII Masker initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43c7b51f-f414-471c-82f1-ecc54e774566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking Pipeline class created successfully!\n"
     ]
    }
   ],
   "source": [
    "class FullReversibleMaskingPipeline:\n",
    "    \"\"\"Enhanced pipeline with full reversibility for all PII types\"\"\"\n",
    "    \n",
    "    def __init__(self, enhanced_masker, detected_pii):\n",
    "        self.masker = enhanced_masker\n",
    "        self.detected_pii = detected_pii\n",
    "        \n",
    "        # Column maskers mapping\n",
    "        self.column_maskers = {\n",
    "            'full_name': self.masker.mask_name_bulletproof,\n",
    "            'doctor_name': self.masker.mask_name_bulletproof,\n",
    "            'address_street': self.masker.mask_address_bulletproof,\n",
    "            'address_city': self.masker.mask_address_bulletproof,\n",
    "            'address_zip': self.masker.mask_address_bulletproof,\n",
    "            'date_of_birth': self.masker.mask_date_bulletproof,\n",
    "            'admission_date': self.masker.mask_date_bulletproof,\n",
    "            'discharge_date': self.masker.mask_date_bulletproof,\n",
    "            'phone_number': self.masker.mask_phone_bulletproof,\n",
    "            'email_address': self.masker.mask_email_bulletproof,\n",
    "            'ssn': self.masker.mask_ssn_bulletproof,\n",
    "            'license_number': self.masker.mask_license_bulletproof,\n",
    "            'vehicle_id': self.masker.mask_vehicle_id_bulletproof,\n",
    "            'device_serial_number': self.masker.mask_device_serial_bulletproof,\n",
    "            'ip_address': self.masker.mask_ip_address_bulletproof,\n",
    "            'hospital_name': self.masker.mask_name_bulletproof,\n",
    "            'insurance_provider': self.masker.mask_name_bulletproof\n",
    "        }\n",
    "    \n",
    "    def mask_dataframe(self, df):\n",
    "        \"\"\"Apply bulletproof masking to the entire dataframe\"\"\"\n",
    "        masked_df = df.copy()\n",
    "        masking_report = {}\n",
    "        \n",
    "        print(\"Starting BULLETPROOF masking process...\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for column in df.columns:\n",
    "            if column in self.column_maskers:\n",
    "                print(f\"Masking column: {column}\")\n",
    "                \n",
    "                mask_function = self.column_maskers[column]\n",
    "                \n",
    "                try:\n",
    "                    masked_values = []\n",
    "                    original_values = df[column].tolist()\n",
    "                    \n",
    "                    for value in original_values:\n",
    "                        masked_value = mask_function(value)\n",
    "                        masked_values.append(masked_value)\n",
    "                    \n",
    "                    masked_df[column] = masked_values\n",
    "                    \n",
    "                    length_errors = 0\n",
    "                    for orig, masked in zip(original_values, masked_values):\n",
    "                        if not pd.isna(orig) and not pd.isna(masked):\n",
    "                            if len(str(orig).strip()) != len(str(masked).strip()):\n",
    "                                length_errors += 1\n",
    "                    \n",
    "                    non_null_original = df[column].dropna().head(3).tolist()\n",
    "                    non_null_masked = pd.Series(masked_values).dropna().head(3).tolist()\n",
    "                    \n",
    "                    masking_report[column] = {\n",
    "                        'status': 'success',\n",
    "                        'total_rows': len(df),\n",
    "                        'length_errors': length_errors,\n",
    "                        'sample_original': non_null_original,\n",
    "                        'sample_masked': non_null_masked\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"  Successfully masked {len(masked_values)} values\")\n",
    "                    if length_errors > 0:\n",
    "                        print(f\"  {length_errors} length mismatches detected\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  Error masking column {column}: {str(e)}\")\n",
    "                    masking_report[column] = {\n",
    "                        'status': 'error',\n",
    "                        'error': str(e)\n",
    "                    }\n",
    "            else:\n",
    "                print(f\"Keeping original: {column} (not PII)\")\n",
    "                masking_report[column] = {'status': 'unchanged'}\n",
    "        \n",
    "        print(f\"\\nBulletproof masking completed!\")\n",
    "        return masked_df, masking_report\n",
    "    \n",
    "    def display_masking_report(self, masking_report):\n",
    "        \"\"\"Display detailed masking report\"\"\"\n",
    "        print(\"\\nBulletproof Masking Report:\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        total_length_errors = 0\n",
    "        \n",
    "        for column, report in masking_report.items():\n",
    "            print(f\"\\nColumn: {column}\")\n",
    "            print(f\"Status: {report['status']}\")\n",
    "            \n",
    "            if report['status'] == 'success':\n",
    "                length_errors = report.get('length_errors', 0)\n",
    "                total_length_errors += length_errors\n",
    "                \n",
    "                print(f\"Length errors: {length_errors}\")\n",
    "                print(f\"Original samples: {report['sample_original']}\")\n",
    "                print(f\"Masked samples:   {report['sample_masked']}\")\n",
    "            elif report['status'] == 'error':\n",
    "                print(f\"Error: {report['error']}\")\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        if total_length_errors == 0:\n",
    "            print(\"PERFECT! No length preservation errors!\")\n",
    "        else:\n",
    "            print(f\"Total length errors across all columns: {total_length_errors}\")\n",
    "\n",
    "print(\"Masking Pipeline class created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "815a1a44-45d3-4b84-94e7-859de0aa7613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Enhanced Masking with Encryption...\n",
      "\n",
      "============================================================\n",
      "ENCRYPTION SETUP\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter encryption password for this dataset:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption key generated from password\n",
      "\n",
      "============================================================\n",
      "APPLYING MASKING\n",
      "============================================================\n",
      "Starting BULLETPROOF masking process...\n",
      "--------------------------------------------------\n",
      "Masking column: full_name\n",
      "  Successfully masked 5000 values\n",
      "Masking column: address_street\n",
      "  Successfully masked 5000 values\n",
      "Masking column: address_city\n",
      "  Successfully masked 5000 values\n",
      "Masking column: address_zip\n",
      "  Successfully masked 5000 values\n",
      "Masking column: date_of_birth\n",
      "  Successfully masked 5000 values\n",
      "Masking column: admission_date\n",
      "  Successfully masked 5000 values\n",
      "Masking column: discharge_date\n",
      "  Successfully masked 5000 values\n",
      "Masking column: phone_number\n",
      "  Successfully masked 5000 values\n",
      "Masking column: email_address\n",
      "  Successfully masked 5000 values\n",
      "Masking column: ssn\n",
      "  Successfully masked 5000 values\n",
      "Keeping original: medical_record_number (not PII)\n",
      "Keeping original: health_plan_id (not PII)\n",
      "Keeping original: account_number (not PII)\n",
      "Masking column: license_number\n",
      "  Successfully masked 5000 values\n",
      "Masking column: vehicle_id\n",
      "  Successfully masked 5000 values\n",
      "Masking column: device_serial_number\n",
      "  Successfully masked 5000 values\n",
      "Masking column: ip_address\n",
      "  Successfully masked 5000 values\n",
      "Keeping original: age (not PII)\n",
      "Keeping original: gender (not PII)\n",
      "Masking column: hospital_name\n",
      "  Successfully masked 5000 values\n",
      "Masking column: doctor_name\n",
      "  Successfully masked 5000 values\n",
      "Keeping original: billing_amount (not PII)\n",
      "Masking column: insurance_provider\n",
      "  Successfully masked 5000 values\n",
      "\n",
      "Bulletproof masking completed!\n",
      "\n",
      "Bulletproof Masking Report:\n",
      "======================================================================\n",
      "\n",
      "Column: full_name\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['Irene Hudson', 'Archie Daugherty', 'Bill Kuhlman']\n",
      "Masked samples:   ['Hqzqr Cdxhoj', 'Kjnzuo Ykduvjlkn', 'Qvqp Worjldl']\n",
      "\n",
      "Column: address_street\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['7426 Arno Extension', '9686 W Pine Street', '64980 Wilkinson Inlet']\n",
      "Masked samples:   ['9059 oWRc gVtNroEcF', '4427 I aVql vcyBMg', '33554 EyXaxEZeU uBNTT']\n",
      "\n",
      "Column: address_city\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['Burdetteport', 'Littelcester', 'North Giovannyberg']\n",
      "Masked samples:   ['fQRfjugjrimf', 'fLENNvwwNpZK', 'BErus WCFGkOtMBhfR']\n",
      "\n",
      "Column: address_zip\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['22012-0821', '24953', '19788']\n",
      "Masked samples:   ['22710-9601', '54698', '49391']\n",
      "\n",
      "Column: date_of_birth\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['1969-03-14T16:03:18.532Z', '1958-05-18T03:04:52.507Z', '1963-10-22T00:44:57.178Z']\n",
      "Masked samples:   ['9816-62-19T59:49:47.213Z', '0786-25-90T88:01:25.222Z', '2842-65-14T59:70:79.851Z']\n",
      "\n",
      "Column: admission_date\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['2022-08-23T23:15:32.763Z', '2023-05-22T17:41:29.702Z', '2022-05-21T21:43:42.320Z']\n",
      "Masked samples:   ['5383-53-28T37:74:26.258Z', '0709-04-89T00:82:50.561Z', '8014-36-15T60:44:32.473Z']\n",
      "\n",
      "Column: discharge_date\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['2020-09-05T23:19:34.848Z', '2020-06-15T03:06:28.941Z', '2021-03-24T14:35:35.583Z']\n",
      "Masked samples:   ['9398-63-17T91:37:14.954Z', '6243-89-80T92:78:21.503Z', '8852-66-09T32:63:46.430Z']\n",
      "\n",
      "Column: phone_number\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['864.363.3035 x87849', '564.262.3039 x34738', '(230) 478-7562']\n",
      "Masked samples:   ['369.685.1576 x77868', '760.351.6542 x62813', '(076) 645-4059']\n",
      "\n",
      "Column: email_address\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['Kiley11@gmail.com', 'Colt40@yahoo.com', 'Kristy_Witting85@gmail.com']\n",
      "Masked samples:   ['zpbbs86@tjcqr.ylw', 'wyhz07@pleck.cwz', 'kqrnna_dlbkxkm89@bdwpq.ddk']\n",
      "\n",
      "Column: ssn\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['tabesco', 'desparatus', 'astrum']\n",
      "Masked samples:   ['cmuspci', 'wqyxdyiqsl', 'umwpsh']\n",
      "\n",
      "Column: medical_record_number\n",
      "Status: unchanged\n",
      "\n",
      "Column: health_plan_id\n",
      "Status: unchanged\n",
      "\n",
      "Column: account_number\n",
      "Status: unchanged\n",
      "\n",
      "Column: license_number\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['qeZMeoN7Ms', '39rwOi1v8g', 'i5sETgPdij']\n",
      "Masked samples:   ['ztFRjpN7Xa', '35blHj0t4k', 'p1rDPxOkac']\n",
      "\n",
      "Column: vehicle_id\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['NDYW3EFWG6JN34965', '00LMPBK2DLLD75760', 'KBL13ER03TU001038']\n",
      "Masked samples:   ['IJBW4HDDL8WC21141', '94BXWBX7PWGO57943', 'QDR51TC99JB266990']\n",
      "\n",
      "Column: device_serial_number\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['Xh1hrTgK531h', 'sxSK3EWdQ1nz', 'Rn4gKu88cNxO']\n",
      "Masked samples:   ['Th2msViU064h', 'efLS8NBnY0nq', 'Br1uXo73dAeN']\n",
      "\n",
      "Column: ip_address\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['129.135.31.111', '34ad:5dca:5443:892e:acfe:4dda:dc75:026a', '2fd8:b4ff:3018:4bfd:af95:2b1a:dcea:10d1']\n",
      "Masked samples:   ['13.148.153.113', '2fd7:2d43:aadd:5068:2bf2:8fb6:c7c1:3a4c', '94e3:4314:74d7:3a46:d596:b68c:dde3:c031']\n",
      "\n",
      "Column: age\n",
      "Status: unchanged\n",
      "\n",
      "Column: gender\n",
      "Status: unchanged\n",
      "\n",
      "Column: hospital_name\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['Friesen LLC', 'Hackett Group', 'Spinka LLC']\n",
      "Masked samples:   ['Inyhjfh Zuu', 'Bekuymd Bvaua', 'Fzbksr Lfy']\n",
      "\n",
      "Column: doctor_name\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['Earl Welch', 'Ira Mayer', 'Mildred Osinski']\n",
      "Masked samples:   ['Wuhf Vqjjz', 'Who Rgdgi', 'Qkrcapr Tjpivuc']\n",
      "\n",
      "Column: billing_amount\n",
      "Status: unchanged\n",
      "\n",
      "Column: insurance_provider\n",
      "Status: success\n",
      "Length errors: 0\n",
      "Original samples: ['Wiegand, Weimann and Heller', 'Haag, Wyman and Paucek', 'Keebler LLC']\n",
      "Masked samples:   ['Szuwnpom Lpjdsin Iub Edffqz', 'Psmlj Zkhhn Pnr Dfgrpu', 'Jybqsmw Tdk']\n",
      "\n",
      "======================================================================\n",
      "PERFECT! No length preservation errors!\n",
      "\n",
      "✅ Masked dataset saved to: ../results\\masked_dataset_2ffd3559_20250913_130516.csv\n",
      "\n",
      "============================================================\n",
      "ENCRYPTING MAPPINGS\n",
      "============================================================\n",
      "Mapping categories created:\n",
      "  names: 18137 mappings\n",
      "  addresses: 14516 mappings\n",
      "  emails: 4999 mappings\n",
      "  phone_numbers: 5000 mappings\n",
      "  ssn_numbers: 993 mappings\n",
      "  license_numbers: 5000 mappings\n",
      "  vehicle_ids: 5000 mappings\n",
      "  device_serials: 5000 mappings\n",
      "  ip_addresses: 5000 mappings\n",
      "  dates: 15000 mappings\n",
      "Mappings encrypted successfully\n",
      "Encrypted mappings saved to: ../config/encrypted_mappings_2ffd3559.json\n",
      "Key info saved to: ../config/key_info_2ffd3559.json\n",
      "✅ Encrypted mappings saved to: ../config/encrypted_mappings_2ffd3559.json\n",
      "✅ Key info saved to: ../config/key_info_2ffd3559.json\n",
      "✅ Session info saved to: ../config/session_info_2ffd3559.json\n",
      "\n",
      "============================================================\n",
      "MASKING COMPLETE!\n",
      "============================================================\n",
      "📁 Session ID: 2ffd3559\n",
      "📁 Masked dataset: ../results\\masked_dataset_2ffd3559_20250913_130516.csv\n",
      "🔒 Encrypted mappings: ../config/encrypted_mappings_2ffd3559.json\n",
      "📋 Session info: ../config/session_info_2ffd3559.json\n",
      "\n",
      "💡 To reverse this dataset, use the reversal function with:\n",
      "   - Session ID: 2ffd3559\n",
      "   - Your encryption password\n"
     ]
    }
   ],
   "source": [
    "if 'df' in locals() and df is not None and 'detected_pii' in locals():\n",
    "    print(\"Applying Enhanced Masking with Encryption...\")\n",
    "    \n",
    "    # Step 1: Generate encryption key from user password\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ENCRYPTION SETUP\")\n",
    "    print(\"=\"*60)\n",
    "    encryption_system.generate_encryption_key()\n",
    "    \n",
    "    # Step 2: Create masking pipeline\n",
    "    pipeline = FullReversibleMaskingPipeline(enhanced_masker, detected_pii)\n",
    "    \n",
    "    # Step 3: Apply masking\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"APPLYING MASKING\")\n",
    "    print(\"=\"*60)\n",
    "    masked_df, masking_report = pipeline.mask_dataframe(df)\n",
    "    \n",
    "    # Step 4: Display masking report\n",
    "    pipeline.display_masking_report(masking_report)\n",
    "    \n",
    "    # Step 5: Save masked dataset to results folder\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    masked_filename = f\"masked_dataset_{SESSION_ID}_{timestamp}.csv\"\n",
    "    masked_filepath = os.path.join('../results', masked_filename)\n",
    "    \n",
    "    masked_df.to_csv(masked_filepath, index=False)\n",
    "    print(f\"\\n✅ Masked dataset saved to: {masked_filepath}\")\n",
    "    \n",
    "    # Step 6: Encrypt and save mappings\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ENCRYPTING MAPPINGS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get all mappings from the masker\n",
    "    all_mappings = enhanced_masker.mappings\n",
    "    \n",
    "    # Display mapping statistics\n",
    "    print(\"Mapping categories created:\")\n",
    "    for category, mappings in all_mappings.items():\n",
    "        if mappings:\n",
    "            print(f\"  {category}: {len(mappings)} mappings\")\n",
    "    \n",
    "    # Encrypt the mappings\n",
    "    encryption_success = encryption_system.encrypt_mappings(all_mappings)\n",
    "    \n",
    "    if encryption_success:\n",
    "        # Save encrypted mappings\n",
    "        encrypted_mappings_path = f'../config/encrypted_mappings_{SESSION_ID}.json'\n",
    "        encryption_system.save_encrypted_mappings(encrypted_mappings_path)\n",
    "        \n",
    "        # Save key info (not the actual key)\n",
    "        key_info_path = f'../config/key_info_{SESSION_ID}.json'\n",
    "        encryption_system.save_key_info(key_info_path)\n",
    "        \n",
    "        print(f\"✅ Encrypted mappings saved to: {encrypted_mappings_path}\")\n",
    "        print(f\"✅ Key info saved to: {key_info_path}\")\n",
    "        \n",
    "        # Step 7: Save session info for easy reversal\n",
    "        session_info = {\n",
    "            'session_id': SESSION_ID,\n",
    "            'timestamp': timestamp,\n",
    "            'original_dataset_shape': df.shape,\n",
    "            'masked_dataset_path': masked_filepath,\n",
    "            'encrypted_mappings_path': encrypted_mappings_path,\n",
    "            'key_info_path': key_info_path,\n",
    "            'pii_columns_detected': len(detected_pii),\n",
    "            'total_columns': len(df.columns),\n",
    "            'note': 'Use this session info to reverse the dataset with the correct encryption password'\n",
    "        }\n",
    "        \n",
    "        session_info_path = f'../config/session_info_{SESSION_ID}.json'\n",
    "        with open(session_info_path, 'w') as f:\n",
    "            json.dump(session_info, f, indent=2)\n",
    "        \n",
    "        print(f\"✅ Session info saved to: {session_info_path}\")\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"MASKING COMPLETE!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"📁 Session ID: {SESSION_ID}\")\n",
    "        print(f\"📁 Masked dataset: {masked_filepath}\")\n",
    "        print(f\"🔒 Encrypted mappings: {encrypted_mappings_path}\")\n",
    "        print(f\"📋 Session info: {session_info_path}\")\n",
    "        print(f\"\\n💡 To reverse this dataset, use the reversal function with:\")\n",
    "        print(f\"   - Session ID: {SESSION_ID}\")\n",
    "        print(f\"   - Your encryption password\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ Failed to encrypt mappings!\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ Please run the previous cells to load data and detect PII first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7b7fa7e8-96a6-4359-a9a8-eab4493f7d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Reversal Function created successfully!\n",
      "\n",
      "💡 Usage:\n",
      "   reverse_masked_dataset_enhanced()  # Interactive mode\n",
      "   reverse_masked_dataset_enhanced('your_session_id')  # Direct mode\n"
     ]
    }
   ],
   "source": [
    "def reverse_masked_dataset_enhanced(session_id=None, masked_csv_path=None):\n",
    "    \"\"\"\n",
    "    ENHANCED DATA REVERSAL with password protection and session management\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"ENHANCED DATA REVERSAL SYSTEM\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: Get session ID if not provided\n",
    "    if session_id is None:\n",
    "        print(\"Available sessions:\")\n",
    "        config_files = [f for f in os.listdir('../config') if f.startswith('session_info_')]\n",
    "        if not config_files:\n",
    "            print(\"No sessions found!\")\n",
    "            return None, None\n",
    "        \n",
    "        for i, file in enumerate(config_files):\n",
    "            session_id_from_file = file.replace('session_info_', '').replace('.json', '')\n",
    "            with open(f'../config/{file}', 'r') as f:\n",
    "                info = json.load(f)\n",
    "            print(f\"{i+1}. Session ID: {session_id_from_file} ({info['timestamp']})\")\n",
    "        \n",
    "        choice = input(\"\\nEnter session number or session ID: \").strip()\n",
    "        \n",
    "        if choice.isdigit():\n",
    "            choice_idx = int(choice) - 1\n",
    "            if 0 <= choice_idx < len(config_files):\n",
    "                session_id = config_files[choice_idx].replace('session_info_', '').replace('.json', '')\n",
    "            else:\n",
    "                print(\"Invalid choice!\")\n",
    "                return None, None\n",
    "        else:\n",
    "            session_id = choice\n",
    "    \n",
    "    print(f\"\\nUsing Session ID: {session_id}\")\n",
    "    \n",
    "    # Step 2: Load session info\n",
    "    session_info_path = f'../config/session_info_{session_id}.json'\n",
    "    try:\n",
    "        with open(session_info_path, 'r') as f:\n",
    "            session_info = json.load(f)\n",
    "        print(f\"✅ Session info loaded\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ Session info not found: {session_info_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Step 3: Get masked dataset path\n",
    "    if masked_csv_path is None:\n",
    "        masked_csv_path = session_info['masked_dataset_path']\n",
    "    \n",
    "    print(f\"📁 Masked dataset: {masked_csv_path}\")\n",
    "    \n",
    "    # Step 4: Load masked data\n",
    "    try:\n",
    "        masked_df = pd.read_csv(masked_csv_path)\n",
    "        print(f\"✅ Loaded masked dataset: {masked_df.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ Masked dataset not found: {masked_csv_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Step 5: Load encrypted mappings\n",
    "    encrypted_mappings_path = session_info['encrypted_mappings_path']\n",
    "    temp_encryption = PIIEncryptionSystem()\n",
    "    \n",
    "    mappings_loaded = temp_encryption.load_encrypted_mappings(encrypted_mappings_path)\n",
    "    if not mappings_loaded:\n",
    "        print(f\"❌ Encrypted mappings not found: {encrypted_mappings_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Step 6: Get password and decrypt\n",
    "    print(f\"\\n🔒 DECRYPTION REQUIRED\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    max_attempts = 3\n",
    "    for attempt in range(max_attempts):\n",
    "        password = getpass.getpass(f\"Enter encryption password (attempt {attempt+1}/{max_attempts}): \")\n",
    "        \n",
    "        decrypted_mappings = temp_encryption.decrypt_mappings_with_password(password)\n",
    "        \n",
    "        if decrypted_mappings is not None:\n",
    "            print(\"✅ Password correct! Mappings decrypted successfully\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"❌ Incorrect password! {max_attempts - attempt - 1} attempts remaining\")\n",
    "            if attempt == max_attempts - 1:\n",
    "                print(\"❌ Maximum attempts reached. Reversal failed.\")\n",
    "                return None, None\n",
    "    \n",
    "    # Step 7: Create reverse mappings\n",
    "    reverse_mappings = temp_encryption.reverse_mappings(decrypted_mappings)\n",
    "    \n",
    "    print(f\"\\n📊 Available mapping categories:\")\n",
    "    for category, mappings in reverse_mappings.items():\n",
    "        if mappings:\n",
    "            print(f\"  {category}: {len(mappings)} mappings\")\n",
    "    \n",
    "    # Step 8: Enhanced column to category mapping\n",
    "    column_categories = {\n",
    "        'full_name': 'names',\n",
    "        'doctor_name': 'names',\n",
    "        'address_street': 'addresses', \n",
    "        'address_city': 'addresses',\n",
    "        'address_zip': 'addresses',\n",
    "        'email_address': 'emails',\n",
    "        'phone_number': 'phone_numbers',\n",
    "        'ssn': 'ssn_numbers',\n",
    "        'license_number': 'license_numbers',\n",
    "        'vehicle_id': 'vehicle_ids',\n",
    "        'device_serial_number': 'device_serials',\n",
    "        'ip_address': 'ip_addresses',\n",
    "        'hospital_name': 'names',\n",
    "        'insurance_provider': 'names',\n",
    "        'date_of_birth': 'dates',\n",
    "        'admission_date': 'dates',\n",
    "        'discharge_date': 'dates'\n",
    "    }\n",
    "    \n",
    "    # Step 9: Apply enhanced reversal\n",
    "    print(f\"\\n🔄 REVERSING DATA\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    recovered_df = masked_df.copy()\n",
    "    reversal_stats = {}\n",
    "    \n",
    "    for column in masked_df.columns:\n",
    "        if column in column_categories:\n",
    "            category = column_categories[column]\n",
    "            \n",
    "            if category in reverse_mappings and reverse_mappings[category]:\n",
    "                print(f\"  Reversing {column} ({category})...\")\n",
    "                \n",
    "                recovered_values = []\n",
    "                successful_reversals = 0\n",
    "                \n",
    "                for value in masked_df[column]:\n",
    "                    if pd.isna(value):\n",
    "                        recovered_values.append(value)\n",
    "                    else:\n",
    "                        value_str = str(value)\n",
    "                        if value_str in reverse_mappings[category]:\n",
    "                            original = reverse_mappings[category][value_str]\n",
    "                            recovered_values.append(original)\n",
    "                            successful_reversals += 1\n",
    "                        else:\n",
    "                            recovered_values.append(value)\n",
    "                \n",
    "                recovered_df[column] = recovered_values\n",
    "                success_rate = (successful_reversals / len(masked_df)) * 100\n",
    "                reversal_stats[column] = {\n",
    "                    'successful': successful_reversals,\n",
    "                    'total': len(masked_df),\n",
    "                    'success_rate': success_rate\n",
    "                }\n",
    "                \n",
    "                print(f\"    ✅ Recovered {successful_reversals}/{len(masked_df)} values ({success_rate:.1f}%)\")\n",
    "            else:\n",
    "                print(f\"    ⚠️ No mappings found for {column}\")\n",
    "                reversal_stats[column] = {'status': 'no_mappings'}\n",
    "        else:\n",
    "            reversal_stats[column] = {'status': 'not_pii'}\n",
    "    \n",
    "    # Step 10: Save recovered data to reversed_datasets folder\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    recovered_filename = f\"recovered_dataset_{session_id}_{timestamp}.csv\"\n",
    "    recovered_filepath = os.path.join('../results/reversed_datasets', recovered_filename)\n",
    "    \n",
    "    recovered_df.to_csv(recovered_filepath, index=False)\n",
    "    \n",
    "    # Step 11: Create recovery report\n",
    "    recovery_report = {\n",
    "        'session_id': session_id,\n",
    "        'recovery_timestamp': timestamp,\n",
    "        'original_masked_file': masked_csv_path,\n",
    "        'recovered_file': recovered_filepath,\n",
    "        'reversal_stats': reversal_stats,\n",
    "        'total_columns': len(masked_df.columns),\n",
    "        'pii_columns_processed': len([col for col in reversal_stats if 'success_rate' in reversal_stats[col]]),\n",
    "        'perfect_reversals': len([col for col in reversal_stats if reversal_stats[col].get('success_rate') == 100])\n",
    "    }\n",
    "    \n",
    "    recovery_report_path = os.path.join('../results/reversed_datasets', f'recovery_report_{session_id}_{timestamp}.json')\n",
    "    with open(recovery_report_path, 'w') as f:\n",
    "        json.dump(recovery_report, f, indent=2)\n",
    "    \n",
    "    # Step 12: Summary\n",
    "    total_pii_columns = recovery_report['pii_columns_processed']\n",
    "    perfect_columns = recovery_report['perfect_reversals']\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"ENHANCED REVERSAL COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"✅ Perfect reversals: {perfect_columns}/{total_pii_columns} PII columns\")\n",
    "    print(f\"📁 Recovered dataset: {recovered_filepath}\")\n",
    "    print(f\"📋 Recovery report: {recovery_report_path}\")\n",
    "    print(f\"🔒 Session ID: {session_id}\")\n",
    "    \n",
    "    return recovered_df, reversal_stats\n",
    "\n",
    "print(\"Enhanced Reversal Function created successfully!\")\n",
    "print(\"\\n💡 Usage:\")\n",
    "print(\"   reverse_masked_dataset_enhanced()  # Interactive mode\")\n",
    "print(\"   reverse_masked_dataset_enhanced('your_session_id')  # Direct mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b924996c-c183-401a-acb4-7bbdd8a7e09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Reversal Function...\n",
      "This will ask for your encryption password to reverse the masked data\n",
      "\n",
      "============================================================\n",
      "ENHANCED DATA REVERSAL SYSTEM\n",
      "============================================================\n",
      "Available sessions:\n",
      "1. Session ID: 2ffd3559 (20250913_130516)\n",
      "2. Session ID: 36a25928 (20250913_130100)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter session number or session ID:  2ffd3559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Session ID: 2ffd3559\n",
      "✅ Session info loaded\n",
      "📁 Masked dataset: ../results\\masked_dataset_2ffd3559_20250913_130516.csv\n",
      "✅ Loaded masked dataset: (5000, 23)\n",
      "Encrypted mappings loaded from: ../config/encrypted_mappings_2ffd3559.json\n",
      "\n",
      "🔒 DECRYPTION REQUIRED\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter encryption password (attempt 1/3):  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mappings decrypted successfully\n",
      "✅ Password correct! Mappings decrypted successfully\n",
      "\n",
      "📊 Available mapping categories:\n",
      "  names: 18137 mappings\n",
      "  addresses: 14482 mappings\n",
      "  emails: 4999 mappings\n",
      "  phone_numbers: 5000 mappings\n",
      "  ssn_numbers: 993 mappings\n",
      "  license_numbers: 5000 mappings\n",
      "  vehicle_ids: 5000 mappings\n",
      "  device_serials: 5000 mappings\n",
      "  ip_addresses: 5000 mappings\n",
      "  dates: 15000 mappings\n",
      "\n",
      "🔄 REVERSING DATA\n",
      "------------------------------\n",
      "  Reversing full_name (names)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "  Reversing address_street (addresses)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "  Reversing address_city (addresses)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "  Reversing address_zip (addresses)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "  Reversing date_of_birth (dates)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "  Reversing admission_date (dates)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "  Reversing discharge_date (dates)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "  Reversing phone_number (phone_numbers)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "  Reversing email_address (emails)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "  Reversing ssn (ssn_numbers)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "  Reversing license_number (license_numbers)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "  Reversing vehicle_id (vehicle_ids)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "  Reversing device_serial_number (device_serials)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "  Reversing ip_address (ip_addresses)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "  Reversing hospital_name (names)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "  Reversing doctor_name (names)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "  Reversing insurance_provider (names)...\n",
      "    ✅ Recovered 5000/5000 values (100.0%)\n",
      "\n",
      "============================================================\n",
      "ENHANCED REVERSAL COMPLETE!\n",
      "============================================================\n",
      "✅ Perfect reversals: 17/17 PII columns\n",
      "📁 Recovered dataset: ../results/reversed_datasets\\recovered_dataset_2ffd3559_20250913_130618.csv\n",
      "📋 Recovery report: ../results/reversed_datasets\\recovery_report_2ffd3559_20250913_130618.json\n",
      "🔒 Session ID: 2ffd3559\n",
      "\n",
      "============================================================\n",
      "REVERSAL TEST RESULTS\n",
      "============================================================\n",
      "Comparing original vs recovered data (first 3 rows):\n",
      "\n",
      "Original data sample:\n",
      "full_name: ['Irene Hudson', 'Archie Daugherty', 'Bill Kuhlman']\n",
      "address_street: ['7426 Arno Extension', '9686 W Pine Street', '64980 Wilkinson Inlet']\n",
      "address_city: ['Burdetteport', 'Littelcester', 'North Giovannyberg']\n",
      "\n",
      "Recovered data sample:\n",
      "full_name: ['Irene Hudson', 'Archie Daugherty', 'Bill Kuhlman']\n",
      "address_street: ['7426 Arno Extension', '9686 W Pine Street', '64980 Wilkinson Inlet']\n",
      "address_city: ['Burdetteport', 'Littelcester', 'North Giovannyberg']\n",
      "\n",
      "✅ Reversal test completed successfully!\n",
      "Reversal test cell ready (uncomment to run)\n"
     ]
    }
   ],
   "source": [
    "# Uncomment and run this cell to test the reversal function\n",
    "\n",
    "\n",
    "# Test the reversal function\n",
    "print(\"Testing Reversal Function...\")\n",
    "print(\"This will ask for your encryption password to reverse the masked data\")\n",
    "\n",
    "# Run the enhanced reversal function\n",
    "recovered_df, reversal_stats = reverse_masked_dataset_enhanced()\n",
    "\n",
    "if recovered_df is not None:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"REVERSAL TEST RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Display some comparison between original and recovered\n",
    "    if 'df' in locals():\n",
    "        print(\"Comparing original vs recovered data (first 3 rows):\")\n",
    "        print(\"\\nOriginal data sample:\")\n",
    "        for col in df.columns[:3]:  # Show first 3 columns\n",
    "            print(f\"{col}: {df[col].head(3).tolist()}\")\n",
    "        \n",
    "        print(\"\\nRecovered data sample:\")\n",
    "        for col in recovered_df.columns[:3]:  # Show first 3 columns\n",
    "            print(f\"{col}: {recovered_df[col].head(3).tolist()}\")\n",
    "    \n",
    "    print(\"\\n✅ Reversal test completed successfully!\")\n",
    "else:\n",
    "    print(\"❌ Reversal test failed!\")\n",
    "\n",
    "print(\"Reversal test cell ready (uncomment to run)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f80cf69-35b6-4a15-949b-64f69f03ab0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility Functions Available:\n",
      "========================================\n",
      "📋 list_sessions() - Show all masking sessions\n",
      "📁 list_results() - Show all result files\n",
      "🧹 clean_old_sessions(5) - Clean old sessions\n",
      "🔍 verify_file_structure() - Check directories\n",
      "\n",
      "Example usage:\n",
      "  list_sessions()\n",
      "  list_results()\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d4e6e7-9236-49bd-8fe4-f393ba67702d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d8b10-5487-4701-800f-784f3cce1d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
